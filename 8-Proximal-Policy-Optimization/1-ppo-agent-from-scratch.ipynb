{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (628573827.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    <video controls autoplay><source src=\"https://huggingface.co/sb3/ppo-LunarLander-v2/resolve/main/replay.mp4\" type=\"video/mp4\"></video>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Here is an example of what we are trying to acheive:\n",
    "# %%html\n",
    "# <video controls autoplay><source src=\"https://huggingface.co/sb3/ppo-LunarLander-v2/resolve/main/replay.mp4\" type=\"video/mp4\"></video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting setuptools==65.5.0\n",
      "  Using cached setuptools-65.5.0-py3-none-any.whl (1.2 MB)\n",
      "Installing collected packages: setuptools\n",
      "Successfully installed setuptools-65.5.0\n"
     ]
    }
   ],
   "source": [
    "# ! pip install setuptools==65.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already installed \n",
    "%%capture\n",
    "# !apt install python-opengl\n",
    "# !apt install ffmpeg\n",
    "# !apt install xvfb\n",
    "# !apt install swig cmake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyglet==1.5 in ./.venv/lib/python3.10/site-packages (1.5.0)\n",
      "Requirement already satisfied: future in ./.venv/lib/python3.10/site-packages (from pyglet==1.5) (0.18.3)\n",
      "Requirement already satisfied: pyvirtualdisplay in ./.venv/lib/python3.10/site-packages (3.0)\n"
     ]
    }
   ],
   "source": [
    "# install virtual display dependencies\n",
    "# !pip install pyglet==1.5\n",
    "# !pip3 install pyvirtualdisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyvirtualdisplay.display.Display at 0x7f342c5eb7f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# virtual display\n",
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(1400, 900))\n",
    "display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym==0.22 in ./.venv/lib/python3.10/site-packages (0.22.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in ./.venv/lib/python3.10/site-packages (from gym==0.22) (1.25.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in ./.venv/lib/python3.10/site-packages (from gym==0.22) (2.2.1)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in ./.venv/lib/python3.10/site-packages (from gym==0.22) (0.0.8)\n",
      "Requirement already satisfied: imageio-ffmpeg in ./.venv/lib/python3.10/site-packages (0.4.8)\n",
      "Requirement already satisfied: huggingface_hub in ./.venv/lib/python3.10/site-packages (0.16.4)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from huggingface_hub) (3.12.2)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.10/site-packages (from huggingface_hub) (2023.6.0)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./.venv/lib/python3.10/site-packages (from huggingface_hub) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.10/site-packages (from huggingface_hub) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.10/site-packages (from huggingface_hub) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.10/site-packages (from huggingface_hub) (23.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests->huggingface_hub) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests->huggingface_hub) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests->huggingface_hub) (2023.5.7)\n",
      "Requirement already satisfied: gym[box2d]==0.22 in ./.venv/lib/python3.10/site-packages (0.22.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in ./.venv/lib/python3.10/site-packages (from gym[box2d]==0.22) (1.25.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in ./.venv/lib/python3.10/site-packages (from gym[box2d]==0.22) (2.2.1)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in ./.venv/lib/python3.10/site-packages (from gym[box2d]==0.22) (0.0.8)\n",
      "Requirement already satisfied: box2d-py==2.3.5 in ./.venv/lib/python3.10/site-packages (from gym[box2d]==0.22) (2.3.5)\n",
      "Requirement already satisfied: pygame==2.1.0 in ./.venv/lib/python3.10/site-packages (from gym[box2d]==0.22) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "# install project dependencies\n",
    "!pip install gym==0.22\n",
    "!pip install imageio-ffmpeg\n",
    "!pip install huggingface_hub\n",
    "!pip install gym[box2d]==0.22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the core implementation of PPO we're going to use the excellent [Costa Huang](https://costa.sh/) tutorial.\n",
    "- In addition to the tutorial, to go deeper you can read the 37 core implementation details: https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/\n",
    "\n",
    "ðŸ‘‰ The video tutorial: https://youtu.be/MEt6rrxH8W4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "# HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/MEt6rrxH8W4\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Hugging Face integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add dependencies we need to push our model to the hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, upload_folder\n",
    "from huggingface_hub.repocard import metadata_eval_result, metadata_save\n",
    "\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import tempfile\n",
    "import json\n",
    "import shutil\n",
    "import imageio_ffmpeg\n",
    "\n",
    "from wasabi import Printer\n",
    "\n",
    "msg = Printer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add new argument in parse_args() function to define the repo-id where we want to push the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16497/821793855.py:4: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "  from distutils.util import strtobool\n"
     ]
    }
   ],
   "source": [
    "# Adding HuggingFace argument\n",
    "import argparse\n",
    "import os\n",
    "from distutils.util import strtobool\n",
    "\n",
    "def parse_args():\n",
    "    # fmt: off\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--exp-name\", type=str, default=os.path.basename(__file__).rstrip(\".py\"), \n",
    "                        help=\"Name of the experiment\")\n",
    "    parser.add_argument(\"--seed\", type=int, default=42, help=\"Seed for reproducibility\")\n",
    "    parser.add_argument(\"--torch-deterministic\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True, help=\"If Toggled, `torch.backends.cudnn.deterministic=False`\")\n",
    "    parser.add_argument(\"--cuda\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
    "        help=\"if toggled, cuda will be enabled by default\")\n",
    "    parser.add_argument(\"--track\", type=lambda x: bool(strtobool(x)), default=False, nargs=\"?\", const=True,\n",
    "        help=\"if toggled, this experiment will be tracked with Weights and Biases\")\n",
    "    parser.add_argument(\"--wandb-project-name\", type=str, default=\"cleanRL\",\n",
    "        help=\"the wandb's project name\")\n",
    "    parser.add_argument(\"--wandb-entity\", type=str, default=None,\n",
    "        help=\"the entity (team) of wandb's project\")\n",
    "    parser.add_argument(\"--capture-video\", type=lambda x: bool(strtobool(x)), default=False, nargs=\"?\", const=True,\n",
    "        help=\"weather to capture videos of the agent performances (check out `videos` folder)\")\n",
    "    \n",
    "    # Alogrithm specific arguments\n",
    "    parser.add_argument(\"--env-id\", type=str, default=\"CartPole-v1\",\n",
    "        help=\"the id of the environment\")\n",
    "    parser.add_argument(\"--total-timesteps\", type=int, default=50000,\n",
    "        help=\"total timesteps of the experiments\")\n",
    "    parser.add_argument(\"--learning-rate\", type=float, default=2.5e-4,\n",
    "        help=\"the learning rate of the optimizer\")\n",
    "    parser.add_argument(\"--num-envs\", type=int, default=4,\n",
    "        help=\"the number of parallel game environments\")\n",
    "    parser.add_argument(\"--num-steps\", type=int, default=128,\n",
    "        help=\"the number of steps to run in each environment per policy rollout\")\n",
    "    parser.add_argument(\"--anneal-lr\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
    "        help=\"Toggle learning rate annealing for policy and value networks\")\n",
    "    parser.add_argument(\"--gae\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
    "        help=\"Use GAE for advantage computation\")\n",
    "    parser.add_argument(\"--gamma\", type=float, default=0.99,\n",
    "        help=\"the discount factor gamma\")\n",
    "    parser.add_argument(\"--gae-lambda\", type=float, default=0.95,\n",
    "        help=\"the lambda for the general advantage estimation\")\n",
    "    parser.add_argument(\"--num-minibatches\", type=int, default=4,\n",
    "        help=\"the number of mini-batches\")\n",
    "    parser.add_argument(\"--update-epochs\", type=int, default=4,\n",
    "        help=\"the K epochs to update the policy\")\n",
    "    parser.add_argument(\"--norm-adv\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
    "        help=\"Toggles advantages normalization\")\n",
    "    parser.add_argument(\"--clip-coef\", type=float, default=0.2,\n",
    "        help=\"the surrogate clipping coefficient\")\n",
    "    parser.add_argument(\"--clip-vloss\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
    "        help=\"Toggles whether or not to use a clipped loss for the value function, as per the paper.\")\n",
    "    parser.add_argument(\"--ent-coef\", type=float, default=0.01,\n",
    "        help=\"coefficient of the entropy\")\n",
    "    parser.add_argument(\"--vf-coef\", type=float, default=0.5,\n",
    "        help=\"coefficient of the value function\")\n",
    "    parser.add_argument(\"--max-grad-norm\", type=float, default=0.5,\n",
    "        help=\"the maximum norm for the gradient clipping\")\n",
    "    parser.add_argument(\"--target-kl\", type=float, default=None,\n",
    "        help=\"the target KL divergence threshold\")\n",
    "\n",
    "    # Adding HuggingFace argument    \n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--repo-id\",\n",
    "        type=str,\n",
    "        default=\"RajkNakka/ppo-LunarLander-v2\",\n",
    "        help=\"id of the model repository from the Hugging Face Hbu {username/repo-name}\",\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    args.batch_size = int(args.num_envs * args.num_steps)\n",
    "    args.minibatch_size = int(args.batch_size // args.num_minibatches)\n",
    "    # fmt: on\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting setuptools==40.8.0\n",
      "  Using cached setuptools-40.8.0-py2.py3-none-any.whl (575 kB)\n",
      "Installing collected packages: setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 65.5.0\n",
      "    Uninstalling setuptools-65.5.0:\n",
      "      Successfully uninstalled setuptools-65.5.0\n",
      "Successfully installed setuptools-40.8.0\n"
     ]
    }
   ],
   "source": [
    "! pip3 install setuptools==40.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
      "Collecting torchaudio\n",
      "  Using cached torchaudio-2.0.2-cp310-cp310-manylinux1_x86_64.whl (4.4 MB)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.10/site-packages (from torch) (4.7.1)\n",
      "Collecting sympy (from torch)\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch)\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch)\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n",
      "  Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91 (from torch)\n",
      "  Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch)\n",
      "  Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch)\n",
      "  Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "Collecting nvidia-nccl-cu11==2.14.3 (from torch)\n",
      "  Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "Collecting nvidia-nvtx-cu11==11.7.91 (from torch)\n",
      "  Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "Collecting triton==2.0.0 (from torch)\n",
      "  Using cached triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (40.8.0)\n",
      "Collecting wheel (from nvidia-cublas-cu11==11.10.3.66->torch)\n",
      "  Using cached wheel-0.40.0-py3-none-any.whl (64 kB)\n",
      "Collecting cmake (from triton==2.0.0->torch)\n",
      "  Using cached cmake-3.26.4-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n",
      "Collecting lit (from triton==2.0.0->torch)\n",
      "  Using cached lit-16.0.6-py3-none-any.whl\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (from torchvision) (1.25.0)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Using cached Pillow-10.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests->torchvision) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests->torchvision) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests->torchvision) (2023.5.7)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, lit, cmake, wheel, sympy, pillow, nvidia-nccl-cu11, nvidia-cufft-cu11, nvidia-cuda-nvrtc-cu11, networkx, MarkupSafe, nvidia-nvtx-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, jinja2, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchvision, torchaudio\n",
      "Successfully installed MarkupSafe-2.1.3 cmake-3.26.4 jinja2-3.1.2 lit-16.0.6 mpmath-1.3.0 networkx-3.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 pillow-10.0.0 sympy-1.12 torch-2.0.1 torchaudio-2.0.2 torchvision-0.15.2 triton-2.0.0 wheel-0.40.0\n"
     ]
    }
   ],
   "source": [
    "! pip3 install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup cuda device\n",
    "# check if gpu is available\n",
    "\"\"\"check if gpu is available\"\"\"\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record video function for uploading to HuggingFace\n",
    "import torch\n",
    "def record_video(env, policy, out_directory, fps=30):\n",
    "    images = []\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    img = env.render(mode=\"rgb_array\")\n",
    "    images.append(img)\n",
    "    while not done:\n",
    "        state = torch.Tensor(state).to(device)\n",
    "        # take the action (index) that have the maximum expected future reward given that state\n",
    "        action, _, _, _ = policy.get_action_and_value(state)\n",
    "        state, reward, done, info = env.step(action.cpu().numpy()) # We directly put next_state = state for recording logic\n",
    "        img = env.render(mode=\"rgb_array\")\n",
    "        images.append(img)\n",
    "    imageio_ffmpeg.imwrite(os.path.join(out_directory, \"preview.jpg\"), [np.array(img) for i, img in enumerate(images)], fps=fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function _generate_model_card definition for Step 5 of the package_to_hub function\n",
    "\n",
    "# First define the dependent generate metadata function which is needed for the _generate_model_card\n",
    "def generate_metadata(model_name, env_id, mean_reward, std_reward):\n",
    "  \"\"\"\n",
    "  Generate the metadata for the model card\n",
    "  :param model_name: name of the model\n",
    "  :env_id: name of the environment\n",
    "  :mean_reward: mean reward of the agent\n",
    "  :std_reward: standard deviation of the mean reward of the agent\n",
    "  \"\"\"\n",
    "  metadata = {}\n",
    "  metadata[\"tags\"] = [\n",
    "    env_id,\n",
    "    \"ppo\",\n",
    "    \"deep-reinforcement-learning\",\n",
    "    \"reinforcement-learning\",\n",
    "    \"custom-implementation\",\n",
    "    \"deep-rl-course\"\n",
    "  ]\n",
    "\n",
    "  # Add metrics\n",
    "  eval = metadata_eval_result(\n",
    "    model_pretty_name=model_name,\n",
    "    task_pretty_name=\"reinfrocement-learning\",\n",
    "    task_id=\"reinforcement-learning\",\n",
    "    metrics_pretty_name=\"mean_reward\",\n",
    "    metrics_id=\"mean_reward\",\n",
    "    metrics_value=f\"{mean_reward:.2f} +/- {std_reward:.2f}\",\n",
    "    dataset_pretty_name=env_id,\n",
    "    dataset_id=env_id,\n",
    "  )\n",
    "\n",
    "  # Merges both dictionaries\n",
    "  metadata = {**metadata, **eval}\n",
    "\n",
    "  return metadata\n",
    "      \n",
    "\n",
    "# generate model card\n",
    "def _generate_model_card(model_name, env_id, mean_reward, std_reward, hyperparameters):\n",
    "  \"\"\"\n",
    "  Generate the model card for the Hub\n",
    "  :param model_name: name of the model\n",
    "  :env_id: name of the environment\n",
    "  :mean_reward: mean reward of the agent\n",
    "  :std_reward: standard deviation of the mean reward of the agent\n",
    "  :hyperparameters: training arguments\n",
    "  \"\"\"\n",
    "  # Step 1: Select the tags\n",
    "  metadata = generate_metadata(model_name, env_id, mean_reward, std_reward)\n",
    "\n",
    "  # Transform the hyperparameters namespace into a string\n",
    "  converted_dict = vars(hyperparameters)\n",
    "  converted_str = str(converted_dict)\n",
    "  converted_str = converted_str.split(\", \")\n",
    "  converted_str = \"\\n\".join(converted_str)\n",
    "\n",
    "  # Step 2: Generate the model card\n",
    "  model_card = f\"\"\"\n",
    "  # PPO Agent Playing {env_id}\n",
    "\n",
    "  This is a trained model of a PPO agent playing {env_id}.\n",
    "\n",
    "  # Hyperparameters\n",
    "  ```python\n",
    "  {converted_str}\n",
    "  ```\n",
    "  \"\"\"\n",
    "  return model_card, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "# Demo:\n",
      "```python\n",
      "Hello world!\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# understanding nested triple quotes\n",
    "str = \"Hello world!\"\n",
    "card = f\"\"\" \n",
    "# Demo:\n",
    "```python\n",
    "{str}\n",
    "```\n",
    "\"\"\"\n",
    "print(card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def package_to_hub(repo_id,\n",
    "                   model,\n",
    "                   hyperparameters,\n",
    "                   eval_env,\n",
    "                   video_fps=30,\n",
    "                   commit_message=\"Push agent to the hub\",\n",
    "                   token=None,\n",
    "                   logs=None\n",
    "                   ):\n",
    "    \"\"\"\n",
    "    Evaluate, Generate a video and upload a model to Hugging Face Hub.\n",
    "    This method does the complete pipeline:\n",
    "    - It evaluates the model\n",
    "    - It generates the model card\n",
    "    - It generates a replay video of the agent\n",
    "    - It pushes everything to the hub\n",
    "    :param repo_id: id of the model repository from the Hugging Face Hub\n",
    "    :param model: trained model\n",
    "    :param eval_env: environment used to evaluate the agent\n",
    "    :param fps: number of fps for rendering the video\n",
    "    :param commit_message: commit message\n",
    "    :param logs: directory on local machine of tensorboard logs you'd like to upload   \n",
    "    \"\"\"\n",
    "\n",
    "    msg.info(\n",
    "        \"This function will save, evaluate, generate a video of your agent, \"\n",
    "        \"create a model card and push everything to the hub. \"\n",
    "        \"It might take up to 1min. \\n \"\n",
    "        \"This is a work in progress: if you encounter a bug, please open an issue.\"\n",
    "    )\n",
    "\n",
    "    # Step 1: Clone or create the repo\n",
    "    repo_url = HfApi().create_repo(\n",
    "        repo_id=repo_id,\n",
    "        token=token,\n",
    "        private=False,\n",
    "        exist_ok=True,\n",
    "    )\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "        tempdirname = Path(tmpdirname)\n",
    "\n",
    "        # Step 2: Save the model\n",
    "        torch.save(model.state_dict(), tempdirname / \"model.pt\")\n",
    "\n",
    "        # Step 3: Evaluate the model and build JSON\n",
    "        mean_reward, std_reward = _evaluate_agent(eval_env,\n",
    "                                                  10,\n",
    "                                                  model)\n",
    "        # First get datetime\n",
    "        eval_datetime = datetime.datetime.now()\n",
    "        # Then convert to string\n",
    "        eval_form_datetime = eval_datetime.isoformat()\n",
    "\n",
    "        # Build JSON\n",
    "        evaluate_data = {\n",
    "            \"env_id\": hyperparameters.env_id,\n",
    "            \"mean_reward\": mean_reward,\n",
    "            \"std_reward\": std_reward,\n",
    "            \"n_eval_episodes\": 10,\n",
    "            \"eval_datetime\": eval_form_datetime,\n",
    "        }\n",
    "\n",
    "        # Write a JSON file\n",
    "        with open(tmpdirname / \"results.json\", \"w\") as f:\n",
    "            json.dump(evaluate_data, f)\n",
    "\n",
    "        # Step 4: Generate a video\n",
    "        video_path = tmpdirname / \"replay.mp4\"\n",
    "        record_video(eval_env, model, video_path, video_fps=video_fps)\n",
    "\n",
    "        # Step 5: Generate a model card\n",
    "        generated_model_card, metadata = _generate_model_card(\"PPO\",\n",
    "\n",
    "        \n",
    "        return repo_url\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
