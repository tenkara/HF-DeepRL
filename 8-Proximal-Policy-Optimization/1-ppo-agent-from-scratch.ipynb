{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (628573827.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    <video controls autoplay><source src=\"https://huggingface.co/sb3/ppo-LunarLander-v2/resolve/main/replay.mp4\" type=\"video/mp4\"></video>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Here is an example of what we are trying to acheive:\n",
    "# %%html\n",
    "# <video controls autoplay><source src=\"https://huggingface.co/sb3/ppo-LunarLander-v2/resolve/main/replay.mp4\" type=\"video/mp4\"></video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting setuptools==65.5.0\n",
      "  Using cached setuptools-65.5.0-py3-none-any.whl (1.2 MB)\n",
      "Installing collected packages: setuptools\n",
      "Successfully installed setuptools-65.5.0\n"
     ]
    }
   ],
   "source": [
    "# ! pip install setuptools==65.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already installed \n",
    "%%capture\n",
    "# !apt install python-opengl\n",
    "# !apt install ffmpeg\n",
    "# !apt install xvfb\n",
    "# !apt install swig cmake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyglet==1.5 in ./.venv/lib/python3.10/site-packages (1.5.0)\n",
      "Requirement already satisfied: future in ./.venv/lib/python3.10/site-packages (from pyglet==1.5) (0.18.3)\n",
      "Requirement already satisfied: pyvirtualdisplay in ./.venv/lib/python3.10/site-packages (3.0)\n"
     ]
    }
   ],
   "source": [
    "# install virtual display dependencies\n",
    "# !pip install pyglet==1.5\n",
    "# !pip3 install pyvirtualdisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyvirtualdisplay.display.Display at 0x7efd68997370>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# virtual display\n",
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(1400, 900))\n",
    "display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym==0.22 in ./.venv/lib/python3.10/site-packages (0.22.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in ./.venv/lib/python3.10/site-packages (from gym==0.22) (1.25.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in ./.venv/lib/python3.10/site-packages (from gym==0.22) (2.2.1)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in ./.venv/lib/python3.10/site-packages (from gym==0.22) (0.0.8)\n",
      "Requirement already satisfied: imageio-ffmpeg in ./.venv/lib/python3.10/site-packages (0.4.8)\n",
      "Requirement already satisfied: huggingface_hub in ./.venv/lib/python3.10/site-packages (0.16.4)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from huggingface_hub) (3.12.2)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.10/site-packages (from huggingface_hub) (2023.6.0)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./.venv/lib/python3.10/site-packages (from huggingface_hub) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.10/site-packages (from huggingface_hub) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.10/site-packages (from huggingface_hub) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.10/site-packages (from huggingface_hub) (23.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests->huggingface_hub) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests->huggingface_hub) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests->huggingface_hub) (2023.5.7)\n",
      "Requirement already satisfied: gym[box2d]==0.22 in ./.venv/lib/python3.10/site-packages (0.22.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in ./.venv/lib/python3.10/site-packages (from gym[box2d]==0.22) (1.25.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in ./.venv/lib/python3.10/site-packages (from gym[box2d]==0.22) (2.2.1)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in ./.venv/lib/python3.10/site-packages (from gym[box2d]==0.22) (0.0.8)\n",
      "Requirement already satisfied: box2d-py==2.3.5 in ./.venv/lib/python3.10/site-packages (from gym[box2d]==0.22) (2.3.5)\n",
      "Requirement already satisfied: pygame==2.1.0 in ./.venv/lib/python3.10/site-packages (from gym[box2d]==0.22) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "# install project dependencies\n",
    "!pip install gym==0.22\n",
    "!pip install imageio-ffmpeg\n",
    "!pip install huggingface_hub\n",
    "!pip install gym[box2d]==0.22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the core implementation of PPO we're going to use the excellent [Costa Huang](https://costa.sh/) tutorial.\n",
    "- In addition to the tutorial, to go deeper you can read the 37 core implementation details: https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/\n",
    "\n",
    "üëâ The video tutorial: https://youtu.be/MEt6rrxH8W4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "# HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/MEt6rrxH8W4\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Hugging Face integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add dependencies we need to push our model to the hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Using cached wandb-0.15.5-py3-none-any.whl (2.1 MB)\n",
      "Collecting Click!=8.0.0,>=7.1 (from wandb)\n",
      "  Using cached click-8.1.4-py3-none-any.whl (98 kB)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Using cached GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in ./.venv/lib/python3.10/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in ./.venv/lib/python3.10/site-packages (from wandb) (5.9.5)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
      "  Using cached sentry_sdk-1.27.1-py2.py3-none-any.whl (211 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: PyYAML in ./.venv/lib/python3.10/site-packages (from wandb) (6.0)\n",
      "Collecting pathtools (from wandb)\n",
      "  Using cached pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.10/site-packages (from wandb) (68.0.0)\n",
      "Collecting appdirs>=1.4.3 (from wandb)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting protobuf!=4.21.0,<5,>=3.19.0 (from wandb)\n",
      "  Using cached protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
      "Requirement already satisfied: six>=1.4.0 in ./.venv/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.5.7)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: pathtools\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=be176beb22b9e07c3d16a689ce691462799e9a2a9d3523c162f5f657a139a465\n",
      "  Stored in directory: /home/raj/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
      "Successfully built pathtools\n",
      "Installing collected packages: pathtools, appdirs, smmap, setproctitle, sentry-sdk, protobuf, docker-pycreds, Click, gitdb, GitPython, wandb\n",
      "Successfully installed Click-8.1.4 GitPython-3.1.31 appdirs-1.4.4 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 protobuf-4.23.4 sentry-sdk-1.27.1 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.5\n"
     ]
    }
   ],
   "source": [
    "# Install Weights and Biases package as that is an optional dependency passed in as a flag to the training script through the main function\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.10/site-packages (40.8.0)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-68.0.0-py3-none-any.whl (804 kB)\n",
      "Installing collected packages: setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 40.8.0\n",
      "    Uninstalling setuptools-40.8.0:\n",
      "      Successfully uninstalled setuptools-40.8.0\n",
      "Successfully installed setuptools-68.0.0\n"
     ]
    }
   ],
   "source": [
    "# Install the latest version of setuptools to avoid the error above installing wandb\n",
    "! pip install --upgrade setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define make_env function needed to setup the environment in the main function\n",
    "def make_env(env_id, seed, idx, capture_video, run_name):\n",
    "    def thunk():\n",
    "        env = gym.make(env_id)\n",
    "        env = gym.wrappers.RecordEpisodeStatistics(env)\n",
    "        if capture_video:\n",
    "            if idx == 0:\n",
    "                env = gym.wrappers.Monitor(env, f\"videos/{run_name}\")\n",
    "        env.seed(seed)\n",
    "        env.action_space.seed(seed)\n",
    "        env.observation_space.seed(seed)\n",
    "        return env\n",
    "    return thunk\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Agent class that will be called from the main function\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class Agent(nn.Module):\n",
    "    def __init__(self, envs):\n",
    "        super().__init__()\n",
    "        self.critic = nn.Sequential(\n",
    "            layer_init(nn.Linear(np.array(envs.single_observation_space.shape).prod(), 64)),\n",
    "            nn.Tanh(),\n",
    "            layer_init(nn.Linear(64, 64)),\n",
    "            nn.Tanh(),\n",
    "            layer_init(nn.Linear(64, 1), std=1.0),\n",
    "        )\n",
    "        self.actor = nn.Sequential(\n",
    "            layer_init(nn.Linear(np.array(envs.single_observation_space.shape).prod(), 64)),\n",
    "            nn.Tanh(),\n",
    "            layer_init(nn.Linear(64, 64)),\n",
    "            nn.Tanh(),\n",
    "            layer_init(nn.Linear(64, envs.single_action_space.n), std=0.01),\n",
    "        )\n",
    "\n",
    "    def get_value(self, x):\n",
    "        return self.critic(x)\n",
    "    \n",
    "    def get_action_and_value(self, x, action=None):\n",
    "        logits = self.actor(x)\n",
    "        probs = Categorical(logits=logits)\n",
    "        if action is None:\n",
    "            action = probs.sample()\n",
    "        return action, probs.log_prob(action), probs.entropy(), self.critic(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main function\n",
    "# Imports needed for functions defined below\n",
    "\n",
    "from huggingface_hub import HfApi, upload_folder\n",
    "from huggingface_hub.repocard import metadata_eval_result, metadata_save\n",
    "\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import tempfile\n",
    "import json\n",
    "import shutil\n",
    "import imageio_ffmpeg\n",
    "import random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.distributions.categorical as Categorical\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from wasabi import Printer\n",
    "\n",
    "msg = Printer()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    run_name = f\"{args.env_id}__{args.exp_name}__{args.seed}__{int(time.time())}\"\n",
    "    if args.track:\n",
    "        import wandb\n",
    "\n",
    "        wandb.init(\n",
    "            project=args.wandb_project_name,\n",
    "            entity=args.wandb_entity,\n",
    "            sync_tensorboard=True,\n",
    "            config=vars(args),\n",
    "            name=run_name,\n",
    "            monitor_gym=True,\n",
    "            save_code=True,\n",
    "        )\n",
    "    writer = SummaryWriter(log_dir=f\"runs/{run_name}\")\n",
    "    writer.add_text(\n",
    "        \"hyperparams\", \n",
    "        \"|param|value|\\n|-|-|\\n%s\" % (\"\\n\".join([f\"|{k}|{v}|\" for k, v in vars(args).items()])),\n",
    "    )\n",
    "\n",
    "    # Try not to modify: seeding\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.backends.cudnn.deterministic = args.torch_deterministic\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # env setup\n",
    "    envs = gym.vector.SyncVectorEnv(\n",
    "        [make_env(args.env_id, i, args.seed +i, i, args.capture_video, run_name) for i in range(args.num_envs)]\n",
    "    )\n",
    "    assert isinstance(envs.single_action_space, gym.spaces.Discrete), \"only discrete action space is supported\"\n",
    "\n",
    "    agent = Agent(envs).to(device)\n",
    "    optimizer = optim.Adam(agent.parameters(), lr=args.learning_rate, eps=1e-5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add new argument in parse_args() function to define the repo-id where we want to push the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding HuggingFace argument\n",
    "import argparse\n",
    "import os\n",
    "from distutils.util import strtobool\n",
    "\n",
    "def parse_args():\n",
    "    # fmt: off\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--exp-name\", type=str, default=os.path.basename(__file__).rstrip(\".py\"), \n",
    "                        help=\"Name of the experiment\")\n",
    "    parser.add_argument(\"--seed\", type=int, default=42, help=\"Seed for reproducibility\")\n",
    "    parser.add_argument(\"--torch-deterministic\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True, help=\"If Toggled, `torch.backends.cudnn.deterministic=False`\")\n",
    "    parser.add_argument(\"--cuda\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
    "        help=\"if toggled, cuda will be enabled by default\")\n",
    "    parser.add_argument(\"--track\", type=lambda x: bool(strtobool(x)), default=False, nargs=\"?\", const=True,\n",
    "        help=\"if toggled, this experiment will be tracked with Weights and Biases\")\n",
    "    parser.add_argument(\"--wandb-project-name\", type=str, default=\"cleanRL\",\n",
    "        help=\"the wandb's project name\")\n",
    "    parser.add_argument(\"--wandb-entity\", type=str, default=None,\n",
    "        help=\"the entity (team) of wandb's project\")\n",
    "    parser.add_argument(\"--capture-video\", type=lambda x: bool(strtobool(x)), default=False, nargs=\"?\", const=True,\n",
    "        help=\"weather to capture videos of the agent performances (check out `videos` folder)\")\n",
    "    \n",
    "    # Alogrithm specific arguments\n",
    "    parser.add_argument(\"--env-id\", type=str, default=\"CartPole-v1\",\n",
    "        help=\"the id of the environment\")\n",
    "    parser.add_argument(\"--total-timesteps\", type=int, default=50000,\n",
    "        help=\"total timesteps of the experiments\")\n",
    "    parser.add_argument(\"--learning-rate\", type=float, default=2.5e-4,\n",
    "        help=\"the learning rate of the optimizer\")\n",
    "    parser.add_argument(\"--num-envs\", type=int, default=4,\n",
    "        help=\"the number of parallel game environments\")\n",
    "    parser.add_argument(\"--num-steps\", type=int, default=128,\n",
    "        help=\"the number of steps to run in each environment per policy rollout\")\n",
    "    parser.add_argument(\"--anneal-lr\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
    "        help=\"Toggle learning rate annealing for policy and value networks\")\n",
    "    parser.add_argument(\"--gae\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
    "        help=\"Use GAE for advantage computation\")\n",
    "    parser.add_argument(\"--gamma\", type=float, default=0.99,\n",
    "        help=\"the discount factor gamma\")\n",
    "    parser.add_argument(\"--gae-lambda\", type=float, default=0.95,\n",
    "        help=\"the lambda for the general advantage estimation\")\n",
    "    parser.add_argument(\"--num-minibatches\", type=int, default=4,\n",
    "        help=\"the number of mini-batches\")\n",
    "    parser.add_argument(\"--update-epochs\", type=int, default=4,\n",
    "        help=\"the K epochs to update the policy\")\n",
    "    parser.add_argument(\"--norm-adv\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
    "        help=\"Toggles advantages normalization\")\n",
    "    parser.add_argument(\"--clip-coef\", type=float, default=0.2,\n",
    "        help=\"the surrogate clipping coefficient\")\n",
    "    parser.add_argument(\"--clip-vloss\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
    "        help=\"Toggles whether or not to use a clipped loss for the value function, as per the paper.\")\n",
    "    parser.add_argument(\"--ent-coef\", type=float, default=0.01,\n",
    "        help=\"coefficient of the entropy\")\n",
    "    parser.add_argument(\"--vf-coef\", type=float, default=0.5,\n",
    "        help=\"coefficient of the value function\")\n",
    "    parser.add_argument(\"--max-grad-norm\", type=float, default=0.5,\n",
    "        help=\"the maximum norm for the gradient clipping\")\n",
    "    parser.add_argument(\"--target-kl\", type=float, default=None,\n",
    "        help=\"the target KL divergence threshold\")\n",
    "\n",
    "    # Adding HuggingFace argument    \n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--repo-id\",\n",
    "        type=str,\n",
    "        default=\"RajkNakka/ppo-LunarLander-v2\",\n",
    "        help=\"id of the model repository from the Hugging Face Hbu {username/repo-name}\",\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    args.batch_size = int(args.num_envs * args.num_steps)\n",
    "    args.minibatch_size = int(args.batch_size // args.num_minibatches)\n",
    "    # fmt: on\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting setuptools==40.8.0\n",
      "  Using cached setuptools-40.8.0-py2.py3-none-any.whl (575 kB)\n",
      "Installing collected packages: setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 65.5.0\n",
      "    Uninstalling setuptools-65.5.0:\n",
      "      Successfully uninstalled setuptools-65.5.0\n",
      "Successfully installed setuptools-40.8.0\n"
     ]
    }
   ],
   "source": [
    "! pip3 install setuptools==40.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
      "Collecting torchaudio\n",
      "  Using cached torchaudio-2.0.2-cp310-cp310-manylinux1_x86_64.whl (4.4 MB)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.10/site-packages (from torch) (4.7.1)\n",
      "Collecting sympy (from torch)\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch)\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch)\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n",
      "  Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91 (from torch)\n",
      "  Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch)\n",
      "  Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch)\n",
      "  Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "Collecting nvidia-nccl-cu11==2.14.3 (from torch)\n",
      "  Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "Collecting nvidia-nvtx-cu11==11.7.91 (from torch)\n",
      "  Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "Collecting triton==2.0.0 (from torch)\n",
      "  Using cached triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (40.8.0)\n",
      "Collecting wheel (from nvidia-cublas-cu11==11.10.3.66->torch)\n",
      "  Using cached wheel-0.40.0-py3-none-any.whl (64 kB)\n",
      "Collecting cmake (from triton==2.0.0->torch)\n",
      "  Using cached cmake-3.26.4-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n",
      "Collecting lit (from triton==2.0.0->torch)\n",
      "  Using cached lit-16.0.6-py3-none-any.whl\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (from torchvision) (1.25.0)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Using cached Pillow-10.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests->torchvision) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests->torchvision) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests->torchvision) (2023.5.7)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, lit, cmake, wheel, sympy, pillow, nvidia-nccl-cu11, nvidia-cufft-cu11, nvidia-cuda-nvrtc-cu11, networkx, MarkupSafe, nvidia-nvtx-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, jinja2, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchvision, torchaudio\n",
      "Successfully installed MarkupSafe-2.1.3 cmake-3.26.4 jinja2-3.1.2 lit-16.0.6 mpmath-1.3.0 networkx-3.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 pillow-10.0.0 sympy-1.12 torch-2.0.1 torchaudio-2.0.2 torchvision-0.15.2 triton-2.0.0 wheel-0.40.0\n"
     ]
    }
   ],
   "source": [
    "! pip3 install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup cuda device\n",
    "# check if gpu is available\n",
    "\"\"\"check if gpu is available\"\"\"\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define _evaluate_agent function for Step 3 of the package_to_hub function\n",
    "def _evaluate_agent(env, n_eval_episodes, policy):\n",
    "    \"\"\" Evaluate the agent for ``n_eval_episodes`` episodes and returns the mean and std of the rewards.\n",
    "    :param env: The evaluation environment\n",
    "    :param n_eval_episodes: The number of episodes to evaluate the agent\n",
    "    :param policy: The policy to use to act by the agent\n",
    "    \"\"\"\n",
    "\n",
    "    episode_rewards = []\n",
    "    for episode in range(n_eval_episodes):\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards_ep = 0\n",
    "\n",
    "        while done is False:\n",
    "            state = torch.Tensor(state).to(device)\n",
    "            action, _, _, _ = policy.get_action_and_value(state)\n",
    "            new_state, reward, done, info = env.step(action.cpu().numpy())\n",
    "            total_rewards_ep += reward\n",
    "            if done:\n",
    "                break\n",
    "            state = new_state\n",
    "            episode_rewards.append(total_rewards_ep)\n",
    "        mean_reward = np.mean(episode_rewards)\n",
    "        std_reward = np.std(episode_rewards)\n",
    "\n",
    "    return mean_reward, std_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define record_video() function for Step 4 of the package_to_hub function\n",
    "import torch\n",
    "def record_video(env, policy, out_directory, fps=30):\n",
    "    images = []\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    img = env.render(mode=\"rgb_array\")\n",
    "    images.append(img)\n",
    "    while not done:\n",
    "        state = torch.Tensor(state).to(device)\n",
    "        # take the action (index) that have the maximum expected future reward given that state\n",
    "        action, _, _, _ = policy.get_action_and_value(state)\n",
    "        state, reward, done, info = env.step(action.cpu().numpy()) # We directly put next_state = state for recording logic\n",
    "        img = env.render(mode=\"rgb_array\")\n",
    "        images.append(img)\n",
    "    imageio_ffmpeg.imwrite(os.path.join(out_directory, \"preview.jpg\"), [np.array(img) for i, img in enumerate(images)], fps=fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function _generate_model_card definition for Step 5 of the package_to_hub function\n",
    "\n",
    "# First define the dependent generate metadata function which is needed for the _generate_model_card\n",
    "def generate_metadata(model_name, env_id, mean_reward, std_reward):\n",
    "  \"\"\"\n",
    "  Generate the metadata for the model card\n",
    "  :param model_name: name of the model\n",
    "  :env_id: name of the environment\n",
    "  :mean_reward: mean reward of the agent\n",
    "  :std_reward: standard deviation of the mean reward of the agent\n",
    "  \"\"\"\n",
    "  metadata = {}\n",
    "  metadata[\"tags\"] = [\n",
    "    env_id,\n",
    "    \"ppo\",\n",
    "    \"deep-reinforcement-learning\",\n",
    "    \"reinforcement-learning\",\n",
    "    \"custom-implementation\",\n",
    "    \"deep-rl-course\"\n",
    "  ]\n",
    "\n",
    "  # Add metrics\n",
    "  eval = metadata_eval_result(\n",
    "    model_pretty_name=model_name,\n",
    "    task_pretty_name=\"reinfrocement-learning\",\n",
    "    task_id=\"reinforcement-learning\",\n",
    "    metrics_pretty_name=\"mean_reward\",\n",
    "    metrics_id=\"mean_reward\",\n",
    "    metrics_value=f\"{mean_reward:.2f} +/- {std_reward:.2f}\",\n",
    "    dataset_pretty_name=env_id,\n",
    "    dataset_id=env_id,\n",
    "  )\n",
    "\n",
    "  # Merges both dictionaries\n",
    "  metadata = {**metadata, **eval}\n",
    "\n",
    "  return metadata\n",
    "      \n",
    "\n",
    "# generate model card\n",
    "def _generate_model_card(model_name, env_id, mean_reward, std_reward, hyperparameters):\n",
    "  \"\"\"\n",
    "  Generate the model card for the Hub\n",
    "  :param model_name: name of the model\n",
    "  :env_id: name of the environment\n",
    "  :mean_reward: mean reward of the agent\n",
    "  :std_reward: standard deviation of the mean reward of the agent\n",
    "  :hyperparameters: training arguments\n",
    "  \"\"\"\n",
    "  # Step 1: Select the tags\n",
    "  metadata = generate_metadata(model_name, env_id, mean_reward, std_reward)\n",
    "\n",
    "  # Transform the hyperparameters namespace into a string\n",
    "  converted_dict = vars(hyperparameters)\n",
    "  converted_str = str(converted_dict)\n",
    "  converted_str = converted_str.split(\", \")\n",
    "  converted_str = \"\\n\".join(converted_str)\n",
    "\n",
    "  # Step 2: Generate the model card\n",
    "  model_card = f\"\"\"\n",
    "  # PPO Agent Playing {env_id}\n",
    "\n",
    "  This is a trained model of a PPO agent playing {env_id}.\n",
    "\n",
    "  # Hyperparameters\n",
    "  ```python\n",
    "  {converted_str}\n",
    "  ```\n",
    "  \"\"\"\n",
    "  return model_card, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "# Demo:\n",
      "```python\n",
      "Hello world!\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# understanding nested triple quotes\n",
    "str = \"Hello world!\"\n",
    "card = f\"\"\" \n",
    "# Demo:\n",
    "```python\n",
    "{str}\n",
    "```\n",
    "\"\"\"\n",
    "print(card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function save_model_card needed for step 5 of the package_to_hub function\n",
    "def _save_model_card(local_path, generated_model_card, metadata):\n",
    "    \"\"\"\n",
    "    Saves a model card to the repository.\n",
    "    :param local_path: repository directory\n",
    "    :param generated_model_card: generated model card by _generate_model_card()\n",
    "    :param metadata: generated metadata\n",
    "    \"\"\"\n",
    "\n",
    "    readme_path = local_path / \"README.md\"\n",
    "    readme = \"\"\n",
    "    if readme_path.exists():\n",
    "        with readme_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "            readme = f.read()\n",
    "    else:\n",
    "        readme = generated_model_card\n",
    "\n",
    "    with readme_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(readme)\n",
    "\n",
    "    # Save the metrics to Readme metadata\n",
    "    metadata_save(readme_path, metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function _add_logdir needed for step 6 of the package_to_hub function\n",
    "def _add_logdir(local_path: Path, logdir: Path):\n",
    "    \"\"\"\n",
    "    Adds the logdir to the repository.\n",
    "    :param local_path: repository directory\n",
    "    :param logdir: logdir to add\n",
    "    \"\"\"\n",
    "    if logdir.exists() and logdir.is_dir():\n",
    "        # Add the logdir to the repository under new dir called logs\n",
    "        repo_logdir = local_path / \"logs\"\n",
    "\n",
    "        # Delete current logs if they exist\n",
    "        if repo_logdir.exists():\n",
    "            shutil.rmtree(repo_logdir)\n",
    "\n",
    "        # Copy logdir into repo logdir\n",
    "        shutil.copytree(logdir, repo_logdir)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def package_to_hub(repo_id,\n",
    "                   model,\n",
    "                   hyperparameters,\n",
    "                   eval_env,\n",
    "                   video_fps=30,\n",
    "                   commit_message=\"Push agent to the hub\",\n",
    "                   token=None,\n",
    "                   logs=None\n",
    "                   ):\n",
    "    \"\"\"\n",
    "    Evaluate, Generate a video and upload a model to Hugging Face Hub.\n",
    "    This method does the complete pipeline:\n",
    "    - It evaluates the model\n",
    "    - It generates the model card\n",
    "    - It generates a replay video of the agent\n",
    "    - It pushes everything to the hub\n",
    "    :param repo_id: id of the model repository from the Hugging Face Hub\n",
    "    :param model: trained model\n",
    "    :param eval_env: environment used to evaluate the agent\n",
    "    :param fps: number of fps for rendering the video\n",
    "    :param commit_message: commit message\n",
    "    :param logs: directory on local machine of tensorboard logs you'd like to upload   \n",
    "    \"\"\"\n",
    "\n",
    "    msg.info(\n",
    "        \"This function will save, evaluate, generate a video of your agent, \"\n",
    "        \"create a model card and push everything to the hub. \"\n",
    "        \"It might take up to 1min. \\n \"\n",
    "        \"This is a work in progress: if you encounter a bug, please open an issue.\"\n",
    "    )\n",
    "\n",
    "    # Step 1: Clone or create the repo\n",
    "    repo_url = HfApi().create_repo(\n",
    "        repo_id=repo_id,\n",
    "        token=token,\n",
    "        private=False,\n",
    "        exist_ok=True,\n",
    "    )\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "        tempdirname = Path(tmpdirname)\n",
    "\n",
    "        # Step 2: Save the model\n",
    "        torch.save(model.state_dict(), tempdirname / \"model.pt\")\n",
    "\n",
    "        # Step 3: Evaluate the model and build JSON\n",
    "        mean_reward, std_reward = _evaluate_agent(eval_env,\n",
    "                                                  10,\n",
    "                                                  model)\n",
    "        # First get datetime\n",
    "        eval_datetime = datetime.datetime.now()\n",
    "        # Then convert to string\n",
    "        eval_form_datetime = eval_datetime.isoformat()\n",
    "\n",
    "        # Build JSON\n",
    "        evaluate_data = {\n",
    "            \"env_id\": hyperparameters.env_id,\n",
    "            \"mean_reward\": mean_reward,\n",
    "            \"std_reward\": std_reward,\n",
    "            \"n_eval_episodes\": 10,\n",
    "            \"eval_datetime\": eval_form_datetime,\n",
    "        }\n",
    "\n",
    "        # Write a JSON file\n",
    "        with open(tmpdirname / \"results.json\", \"w\") as f:\n",
    "            json.dump(evaluate_data, f)\n",
    "\n",
    "        # Step 4: Generate a video\n",
    "        video_path = tmpdirname / \"replay.mp4\"\n",
    "        record_video(eval_env, model, video_path, video_fps=video_fps)\n",
    "\n",
    "        # Step 5: Generate a model card\n",
    "        generated_model_card, metadata = _generate_model_card(\"PPO\",\n",
    "                                                                hyperparameters.env_id,\n",
    "                                                                mean_reward,\n",
    "                                                                std_reward,\n",
    "                                                                hyperparameters)\n",
    "        _save_model_card(tmpdirname, generated_model_card, metadata)\n",
    "\n",
    "        # Step 6: Add logs if needed\n",
    "        if logs:\n",
    "            _add_logdir(tmpdirname, Path(logs))\n",
    "\n",
    "        msg.info(f\"Pushing the model to the hub under the id {repo_id}...\")\n",
    "\n",
    "        repo_url = upload_folder(\n",
    "            repo_id=repo_id,\n",
    "            folder_path=tmpdirname,\n",
    "            path_in_repo=\"\",\n",
    "            commit_message=commit_message,\n",
    "            token=token,\n",
    "        )\n",
    "        \n",
    "        msg.info(f\"Your model is pushed to the Hub. You can view your model here: {repo_url}\")\n",
    "        return repo_url\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
