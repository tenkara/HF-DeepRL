{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"https://huggingface.co/edbeeching/doom_health_gathering_supreme_3333/resolve/main/replay.mp4\"\n",
       "  type=\"video/mp4\">Your browser does not support the video tag.</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\n",
    "    \"\"\"<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"https://huggingface.co/edbeeching/doom_health_gathering_supreme_3333/resolve/main/replay.mp4\"\n",
    "  type=\"video/mp4\">Your browser does not support the video tag.</video>\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n"
     ]
    }
   ],
   "source": [
    "# Install ViZDoom deps from\n",
    "# https://github.com/mwydmuch/ViZDoom/blob/master/doc/Building.md#-linux\n",
    "\n",
    "!apt-get install build-essential zlib1g-dev libsdl2-dev libjpeg-dev \\\n",
    "nasm tar libbz2-dev libgtk2.0-dev cmake git libfluidsynth-dev libgme-dev \\\n",
    "libopenal-dev timidity libwildmidi-dev unzip ffmpeg\n",
    "\n",
    "# Boost libraries\n",
    "!apt-get install libboost-all-dev\n",
    "\n",
    "# Lua binding dependencies\n",
    "!apt-get install liblua5.1-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: unsuccessful initial attempt using frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: unsuccessful initial attempt using frozen solve. Retrying with flexible solve.\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - sample-factory\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://repo.anaconda.com/pkgs/main/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! conda install sample-factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: unsuccessful initial attempt using frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: unsuccessful initial attempt using frozen solve. Retrying with flexible solve.\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - sample-factory\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://conda.anaconda.org/conda-forge/linux-64\n",
      "  - https://conda.anaconda.org/conda-forge/noarch\n",
      "  - https://repo.anaconda.com/pkgs/main/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! conda install -c conda-forge sample-factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sample-factory\n",
      "  Downloading sample_factory-2.1.1-py3-none-any.whl (9.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy<2.0,>=1.18.1 (from sample-factory)\n",
      "  Downloading numpy-1.25.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch!=1.13.0,<3.0,>=1.9 (from sample-factory)\n",
      "  Downloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting gymnasium<1.0,>=0.27 (from sample-factory)\n",
      "  Using cached gymnasium-0.28.1-py3-none-any.whl (925 kB)\n",
      "Collecting pyglet (from sample-factory)\n",
      "  Downloading pyglet-2.0.8-py3-none-any.whl (853 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m853.1/853.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard>=1.15.0 (from sample-factory)\n",
      "  Using cached tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "Collecting tensorboardx>=2.0 (from sample-factory)\n",
      "  Downloading tensorboardX-2.6.1-py2.py3-none-any.whl (101 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil>=5.7.0 in ./envs/lib/python3.11/site-packages (from sample-factory) (5.9.0)\n",
      "Collecting threadpoolctl>=2.0.0 (from sample-factory)\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting colorlog (from sample-factory)\n",
      "  Using cached colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting signal-slot-mp<2.0,>=1.0.3 (from sample-factory)\n",
      "  Downloading signal_slot_mp-1.0.5-py3-none-any.whl (13 kB)\n",
      "Collecting filelock (from sample-factory)\n",
      "  Using cached filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "Collecting opencv-python (from sample-factory)\n",
      "  Using cached opencv_python-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n",
      "Collecting wandb>=0.12.9 (from sample-factory)\n",
      "  Using cached wandb-0.15.5-py3-none-any.whl (2.1 MB)\n",
      "Collecting huggingface-hub<1.0,>=0.10.0 (from sample-factory)\n",
      "  Using cached huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "Collecting jax-jumpy>=1.0.0 (from gymnasium<1.0,>=0.27->sample-factory)\n",
      "  Using cached jax_jumpy-1.0.0-py3-none-any.whl (20 kB)\n",
      "Collecting cloudpickle>=1.2.0 (from gymnasium<1.0,>=0.27->sample-factory)\n",
      "  Using cached cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in ./envs/lib/python3.11/site-packages (from gymnasium<1.0,>=0.27->sample-factory) (4.7.1)\n",
      "Collecting farama-notifications>=0.0.1 (from gymnasium<1.0,>=0.27->sample-factory)\n",
      "  Using cached Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Collecting fsspec (from huggingface-hub<1.0,>=0.10.0->sample-factory)\n",
      "  Using cached fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "Collecting requests (from huggingface-hub<1.0,>=0.10.0->sample-factory)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting tqdm>=4.42.1 (from huggingface-hub<1.0,>=0.10.0->sample-factory)\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting pyyaml>=5.1 (from huggingface-hub<1.0,>=0.10.0->sample-factory)\n",
      "  Downloading PyYAML-6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.9/757.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.9 in ./envs/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.10.0->sample-factory) (23.1)\n",
      "Collecting faster-fifo<2.0,>=1.4.4 (from signal-slot-mp<2.0,>=1.0.3->sample-factory)\n",
      "  Downloading faster-fifo-1.4.5.tar.gz (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.0/87.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting absl-py>=0.4 (from tensorboard>=1.15.0->sample-factory)\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard>=1.15.0->sample-factory)\n",
      "  Downloading grpcio-1.56.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3 (from tensorboard>=1.15.0->sample-factory)\n",
      "  Using cached google_auth-2.21.0-py2.py3-none-any.whl (182 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard>=1.15.0->sample-factory)\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard>=1.15.0->sample-factory)\n",
      "  Using cached Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "Collecting protobuf>=3.19.6 (from tensorboard>=1.15.0->sample-factory)\n",
      "  Using cached protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./envs/lib/python3.11/site-packages (from tensorboard>=1.15.0->sample-factory) (67.8.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard>=1.15.0->sample-factory)\n",
      "  Using cached tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard>=1.15.0->sample-factory)\n",
      "  Using cached Werkzeug-2.3.6-py3-none-any.whl (242 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in ./envs/lib/python3.11/site-packages (from tensorboard>=1.15.0->sample-factory) (0.38.4)\n",
      "Collecting sympy (from torch!=1.13.0,<3.0,>=1.9->sample-factory)\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting networkx (from torch!=1.13.0,<3.0,>=1.9->sample-factory)\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Collecting jinja2 (from torch!=1.13.0,<3.0,>=1.9->sample-factory)\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch!=1.13.0,<3.0,>=1.9->sample-factory)\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch!=1.13.0,<3.0,>=1.9->sample-factory)\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch!=1.13.0,<3.0,>=1.9->sample-factory)\n",
      "  Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch!=1.13.0,<3.0,>=1.9->sample-factory)\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch!=1.13.0,<3.0,>=1.9->sample-factory)\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch!=1.13.0,<3.0,>=1.9->sample-factory)\n",
      "  Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91 (from torch!=1.13.0,<3.0,>=1.9->sample-factory)\n",
      "  Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch!=1.13.0,<3.0,>=1.9->sample-factory)\n",
      "  Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch!=1.13.0,<3.0,>=1.9->sample-factory)\n",
      "  Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "Collecting nvidia-nccl-cu11==2.14.3 (from torch!=1.13.0,<3.0,>=1.9->sample-factory)\n",
      "  Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "Collecting nvidia-nvtx-cu11==11.7.91 (from torch!=1.13.0,<3.0,>=1.9->sample-factory)\n",
      "  Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "Collecting triton==2.0.0 (from torch!=1.13.0,<3.0,>=1.9->sample-factory)\n",
      "  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting cmake (from triton==2.0.0->torch!=1.13.0,<3.0,>=1.9->sample-factory)\n",
      "  Using cached cmake-3.26.4-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n",
      "Collecting lit (from triton==2.0.0->torch!=1.13.0,<3.0,>=1.9->sample-factory)\n",
      "  Using cached lit-16.0.6.tar.gz (153 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting Click!=8.0.0,>=7.1 (from wandb>=0.12.9->sample-factory)\n",
      "  Using cached click-8.1.4-py3-none-any.whl (98 kB)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb>=0.12.9->sample-factory)\n",
      "  Using cached GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb>=0.12.9->sample-factory)\n",
      "  Using cached sentry_sdk-1.27.1-py2.py3-none-any.whl (211 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb>=0.12.9->sample-factory)\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting pathtools (from wandb>=0.12.9->sample-factory)\n",
      "  Using cached pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting setproctitle (from wandb>=0.12.9->sample-factory)\n",
      "  Downloading setproctitle-1.3.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Collecting appdirs>=1.4.3 (from wandb>=0.12.9->sample-factory)\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: six>=1.4.0 in ./envs/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb>=0.12.9->sample-factory) (1.16.0)\n",
      "Collecting cython>=0.29 (from faster-fifo<2.0,>=1.4.4->signal-slot-mp<2.0,>=1.0.3->sample-factory)\n",
      "  Using cached Cython-0.29.36-py2.py3-none-any.whl (988 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb>=0.12.9->sample-factory)\n",
      "  Using cached gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard>=1.15.0->sample-factory)\n",
      "  Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard>=1.15.0->sample-factory)\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard>=1.15.0->sample-factory)\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting urllib3<2.0 (from google-auth<3,>=1.6.3->tensorboard>=1.15.0->sample-factory)\n",
      "  Using cached urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=1.15.0->sample-factory)\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->huggingface-hub<1.0,>=0.10.0->sample-factory)\n",
      "  Downloading charset_normalizer-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.6/199.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting idna<4,>=2.5 (from requests->huggingface-hub<1.0,>=0.10.0->sample-factory)\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->huggingface-hub<1.0,>=0.10.0->sample-factory)\n",
      "  Using cached certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard>=1.15.0->sample-factory)\n",
      "  Downloading MarkupSafe-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->torch!=1.13.0,<3.0,>=1.9->sample-factory)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.12.9->sample-factory)\n",
      "  Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.15.0->sample-factory)\n",
      "  Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=1.15.0->sample-factory)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Building wheels for collected packages: faster-fifo, pathtools, lit\n",
      "  Building wheel for faster-fifo (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for faster-fifo: filename=faster_fifo-1.4.5-cp311-cp311-linux_x86_64.whl size=80799 sha256=78f56e6088370056a9bebdeafda9dc481068ba94e26fabbfe2106be1732d9d2d\n",
      "  Stored in directory: /home/raj/.cache/pip/wheels/57/27/d7/fbfcf5256e707efa229aee6a41da6904d415d90759d318f69e\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=762c05e9fde77cbca291597a2ef8dd5e6e2850ca4876a1f68699a8f648fa1ff1\n",
      "  Stored in directory: /home/raj/.cache/pip/wheels/ea/b7/8b/84e94095ea418b9442f5abeba4ca7b0ad52d3fe7b69d6238a6\n",
      "  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-16.0.6-py3-none-any.whl size=93582 sha256=8da5f7ad611a31c24becdb1970f449018958d40b68878b06f4c03146a19aa478\n",
      "  Stored in directory: /home/raj/.cache/pip/wheels/ab/84/e4/5af8c76af9e5bee472e825f1451c18bb3b261d80a7b3ec7f8a\n",
      "Successfully built faster-fifo pathtools lit\n",
      "Installing collected packages: pyglet, pathtools, mpmath, lit, farama-notifications, cmake, appdirs, urllib3, tqdm, threadpoolctl, tensorboard-data-server, sympy, smmap, setproctitle, pyyaml, pyasn1, protobuf, oauthlib, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, networkx, MarkupSafe, markdown, idna, grpcio, fsspec, filelock, docker-pycreds, cython, colorlog, cloudpickle, Click, charset-normalizer, certifi, cachetools, absl-py, werkzeug, tensorboardx, sentry-sdk, rsa, requests, pyasn1-modules, opencv-python, nvidia-cusolver-cu11, nvidia-cudnn-cu11, jinja2, jax-jumpy, gitdb, faster-fifo, signal-slot-mp, requests-oauthlib, huggingface-hub, gymnasium, google-auth, GitPython, wandb, google-auth-oauthlib, tensorboard, triton, torch, sample-factory\n",
      "Successfully installed Click-8.1.4 GitPython-3.1.31 MarkupSafe-2.1.3 absl-py-1.4.0 appdirs-1.4.4 cachetools-5.3.1 certifi-2023.5.7 charset-normalizer-3.2.0 cloudpickle-2.2.1 cmake-3.26.4 colorlog-6.7.0 cython-0.29.36 docker-pycreds-0.4.0 farama-notifications-0.0.4 faster-fifo-1.4.5 filelock-3.12.2 fsspec-2023.6.0 gitdb-4.0.10 google-auth-2.21.0 google-auth-oauthlib-1.0.0 grpcio-1.56.0 gymnasium-0.28.1 huggingface-hub-0.16.4 idna-3.4 jax-jumpy-1.0.0 jinja2-3.1.2 lit-16.0.6 markdown-3.4.3 mpmath-1.3.0 networkx-3.1 numpy-1.25.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 oauthlib-3.2.2 opencv-python-4.8.0.74 pathtools-0.1.2 protobuf-4.23.4 pyasn1-0.5.0 pyasn1-modules-0.3.0 pyglet-2.0.8 pyyaml-6.0 requests-2.31.0 requests-oauthlib-1.3.1 rsa-4.9 sample-factory-2.1.1 sentry-sdk-1.27.1 setproctitle-1.3.2 signal-slot-mp-1.0.5 smmap-5.0.0 sympy-1.12 tensorboard-2.13.0 tensorboard-data-server-0.7.1 tensorboardx-2.6.1 threadpoolctl-3.1.0 torch-2.0.1 tqdm-4.65.0 triton-2.0.0 urllib3-1.26.16 wandb-0.15.5 werkzeug-2.3.6\n",
      "Collecting vizdoom\n",
      "  Downloading vizdoom-1.2.0.tar.gz (15.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in ./envs/lib/python3.11/site-packages (from vizdoom) (1.25.0)\n",
      "Requirement already satisfied: gymnasium>=0.28.0 in ./envs/lib/python3.11/site-packages (from vizdoom) (0.28.1)\n",
      "Collecting pygame>=2.1.3 (from vizdoom)\n",
      "  Downloading pygame-2.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jax-jumpy>=1.0.0 in ./envs/lib/python3.11/site-packages (from gymnasium>=0.28.0->vizdoom) (1.0.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in ./envs/lib/python3.11/site-packages (from gymnasium>=0.28.0->vizdoom) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in ./envs/lib/python3.11/site-packages (from gymnasium>=0.28.0->vizdoom) (4.7.1)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in ./envs/lib/python3.11/site-packages (from gymnasium>=0.28.0->vizdoom) (0.0.4)\n",
      "Building wheels for collected packages: vizdoom\n",
      "  Building wheel for vizdoom (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for vizdoom: filename=vizdoom-1.2.0-cp311-cp311-linux_x86_64.whl size=14212000 sha256=07adf3add1d3079b1e63d8e2b8663d37fc4734f7b062ce58114293bd020ac35c\n",
      "  Stored in directory: /home/raj/.cache/pip/wheels/37/48/c0/e776fb9890eeb38ac80662d8557fd450eabf4d68453b24463c\n",
      "Successfully built vizdoom\n",
      "Installing collected packages: pygame, vizdoom\n",
      "Successfully installed pygame-2.5.0 vizdoom-1.2.0\n"
     ]
    }
   ],
   "source": [
    "! pip install sample-factory\n",
    "! pip install vizdoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "from sample_factory.algo.utils.context import global_model_factory\n",
    "from sample_factory.cfg.arguments import parse_full_cfg, parse_sf_args\n",
    "from sample_factory.envs.env_utils import register_env\n",
    "from sample_factory.train import run_rl\n",
    "\n",
    "from sf_examples.vizdoom.doom.doom_model import make_vizdoom_encoder\n",
    "from sf_examples.vizdoom.doom.doom_params import add_doom_env_args, doom_override_defaults\n",
    "from sf_examples.vizdoom.doom.doom_utils import DOOM_ENVS, make_doom_env_from_spec\n",
    "\n",
    "\n",
    "# Registers all the ViZDoom environments\n",
    "def register_vizdoom_envs():\n",
    "    for env_spec in DOOM_ENVS:\n",
    "        make_env_func = functools.partial(make_doom_env_from_spec, env_spec)\n",
    "        register_env(env_spec.name, make_env_func)\n",
    "\n",
    "\n",
    "# Sample Factory allows the registration of a custom Neural Network architecture\n",
    "# See https://github.com/alex-petrenko/sample-factory/blob/master/sf_examples/vizdoom/doom/doom_model.py for more details\n",
    "def register_vizdoom_models():\n",
    "    global_model_factory().register_encoder_factory(make_vizdoom_encoder)\n",
    "\n",
    "\n",
    "def register_vizdoom_components():\n",
    "    register_vizdoom_envs()\n",
    "    register_vizdoom_models()\n",
    "\n",
    "\n",
    "# parse the command line args and create a config\n",
    "def parse_vizdoom_cfg(argv=None, evaluation=False):\n",
    "    parser, _ = parse_sf_args(argv=argv, evaluation=evaluation)\n",
    "    # parameters specific to Doom envs\n",
    "    add_doom_env_args(parser)\n",
    "    # override Doom default values for algo parameters\n",
    "    doom_override_defaults(parser)\n",
    "    # second parsing pass yields the final configuration\n",
    "    final_cfg = parse_full_cfg(parser, argv)\n",
    "    return final_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[2023-07-08 15:53:29,365][01000] register_encoder_factory: <function make_vizdoom_encoder at 0x7fe47da82a20>\u001b[0m\n",
      "\u001b[33m[2023-07-08 15:53:29,371][01000] Saved parameter configuration for experiment default_experiment not found!\u001b[0m\n",
      "\u001b[33m[2023-07-08 15:53:29,371][01000] Starting experiment from scratch!\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:29,375][01000] Experiment dir /home/raj/repos/HF-DeepRL/8-Proximal-Policy-Optimization/train_dir/default_experiment already exists!\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:29,375][01000] Resuming existing experiment from /home/raj/repos/HF-DeepRL/8-Proximal-Policy-Optimization/train_dir/default_experiment...\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:29,376][01000] Weights and Biases integration disabled\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:30,343][01000] Queried available GPUs: 0\n",
      "\u001b[0m\n",
      "\u001b[37m\u001b[1m[2023-07-08 15:53:30,344][01000] Environment var CUDA_VISIBLE_DEVICES is 0\n",
      "\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:31,159][06913] Doom resolution: 160x120, resize resolution: (128, 72)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:31,159][06913] Env info: EnvInfo(obs_space=Dict('obs': Box(0, 255, (3, 72, 128), uint8)), action_space=Discrete(5), num_agents=1, gpu_actions=False, gpu_observations=True, action_splits=None, all_discrete=None, frameskip=4, reward_shaping_scheme=None, env_info_protocol_version=1)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:31,385][01000] Automatically setting recurrence to 32\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:31,386][01000] Starting experiment with the following configuration:\n",
      "help=False\n",
      "algo=APPO\n",
      "env=doom_health_gathering_supreme\n",
      "experiment=default_experiment\n",
      "train_dir=/home/raj/repos/HF-DeepRL/8-Proximal-Policy-Optimization/train_dir\n",
      "restart_behavior=resume\n",
      "device=gpu\n",
      "seed=None\n",
      "num_policies=1\n",
      "async_rl=True\n",
      "serial_mode=False\n",
      "batched_sampling=False\n",
      "num_batches_to_accumulate=2\n",
      "worker_num_splits=2\n",
      "policy_workers_per_policy=1\n",
      "max_policy_lag=1000\n",
      "num_workers=8\n",
      "num_envs_per_worker=4\n",
      "batch_size=1024\n",
      "num_batches_per_epoch=1\n",
      "num_epochs=1\n",
      "rollout=32\n",
      "recurrence=32\n",
      "shuffle_minibatches=False\n",
      "gamma=0.99\n",
      "reward_scale=1.0\n",
      "reward_clip=1000.0\n",
      "value_bootstrap=False\n",
      "normalize_returns=True\n",
      "exploration_loss_coeff=0.001\n",
      "value_loss_coeff=0.5\n",
      "kl_loss_coeff=0.0\n",
      "exploration_loss=symmetric_kl\n",
      "gae_lambda=0.95\n",
      "ppo_clip_ratio=0.1\n",
      "ppo_clip_value=0.2\n",
      "with_vtrace=False\n",
      "vtrace_rho=1.0\n",
      "vtrace_c=1.0\n",
      "optimizer=adam\n",
      "adam_eps=1e-06\n",
      "adam_beta1=0.9\n",
      "adam_beta2=0.999\n",
      "max_grad_norm=4.0\n",
      "learning_rate=0.0001\n",
      "lr_schedule=constant\n",
      "lr_schedule_kl_threshold=0.008\n",
      "lr_adaptive_min=1e-06\n",
      "lr_adaptive_max=0.01\n",
      "obs_subtract_mean=0.0\n",
      "obs_scale=255.0\n",
      "normalize_input=True\n",
      "normalize_input_keys=None\n",
      "decorrelate_experience_max_seconds=0\n",
      "decorrelate_envs_on_one_worker=True\n",
      "actor_worker_gpus=[]\n",
      "set_workers_cpu_affinity=True\n",
      "force_envs_single_thread=False\n",
      "default_niceness=0\n",
      "log_to_file=True\n",
      "experiment_summaries_interval=10\n",
      "flush_summaries_interval=30\n",
      "stats_avg=100\n",
      "summaries_use_frameskip=True\n",
      "heartbeat_interval=20\n",
      "heartbeat_reporting_interval=600\n",
      "train_for_env_steps=4000000\n",
      "train_for_seconds=10000000000\n",
      "save_every_sec=120\n",
      "keep_checkpoints=2\n",
      "load_checkpoint_kind=latest\n",
      "save_milestones_sec=-1\n",
      "save_best_every_sec=5\n",
      "save_best_metric=reward\n",
      "save_best_after=100000\n",
      "benchmark=False\n",
      "encoder_mlp_layers=[512, 512]\n",
      "encoder_conv_architecture=convnet_simple\n",
      "encoder_conv_mlp_layers=[512]\n",
      "use_rnn=True\n",
      "rnn_size=512\n",
      "rnn_type=gru\n",
      "rnn_num_layers=1\n",
      "decoder_mlp_layers=[]\n",
      "nonlinearity=elu\n",
      "policy_initialization=orthogonal\n",
      "policy_init_gain=1.0\n",
      "actor_critic_share_weights=True\n",
      "adaptive_stddev=True\n",
      "continuous_tanh_scale=0.0\n",
      "initial_stddev=1.0\n",
      "use_env_info_cache=False\n",
      "env_gpu_actions=False\n",
      "env_gpu_observations=True\n",
      "env_frameskip=4\n",
      "env_framestack=1\n",
      "pixel_format=CHW\n",
      "use_record_episode_statistics=False\n",
      "with_wandb=False\n",
      "wandb_user=None\n",
      "wandb_project=sample_factory\n",
      "wandb_group=None\n",
      "wandb_job_type=SF\n",
      "wandb_tags=[]\n",
      "with_pbt=False\n",
      "pbt_mix_policies_in_one_env=True\n",
      "pbt_period_env_steps=5000000\n",
      "pbt_start_mutation=20000000\n",
      "pbt_replace_fraction=0.3\n",
      "pbt_mutation_rate=0.15\n",
      "pbt_replace_reward_gap=0.1\n",
      "pbt_replace_reward_gap_absolute=1e-06\n",
      "pbt_optimize_gamma=False\n",
      "pbt_target_objective=true_objective\n",
      "pbt_perturb_min=1.1\n",
      "pbt_perturb_max=1.5\n",
      "num_agents=-1\n",
      "num_humans=0\n",
      "num_bots=-1\n",
      "start_bot_difficulty=None\n",
      "timelimit=None\n",
      "res_w=128\n",
      "res_h=72\n",
      "wide_aspect_ratio=False\n",
      "eval_env_frameskip=1\n",
      "fps=35\n",
      "command_line=--env=doom_health_gathering_supreme --num_workers=8 --num_envs_per_worker=4 --train_for_env_steps=4000000\n",
      "cli_args={'env': 'doom_health_gathering_supreme', 'num_workers': 8, 'num_envs_per_worker': 4, 'train_for_env_steps': 4000000}\n",
      "git_hash=0401714b01ee832562a0930e3744117f1ba51e10\n",
      "git_repo_name=https://github.com/tenkara/HF-DeepRL.git\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:31,387][01000] Saving configuration to /home/raj/repos/HF-DeepRL/8-Proximal-Policy-Optimization/train_dir/default_experiment/config.json...\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:31,389][01000] Rollout worker 0 uses device cpu\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:31,389][01000] Rollout worker 1 uses device cpu\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:31,390][01000] Rollout worker 2 uses device cpu\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:31,390][01000] Rollout worker 3 uses device cpu\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:31,391][01000] Rollout worker 4 uses device cpu\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:31,391][01000] Rollout worker 5 uses device cpu\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:31,391][01000] Rollout worker 6 uses device cpu\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:31,392][01000] Rollout worker 7 uses device cpu\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:31,425][01000] Using GPUs [0] for process 0 (actually maps to GPUs [0])\u001b[0m\n",
      "\u001b[37m\u001b[1m[2023-07-08 15:53:31,426][01000] InferenceWorker_p0-w0: min num requests: 2\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:31,441][01000] Starting all processes...\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:31,441][01000] Starting process learner_proc0\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:31,491][01000] Starting all processes...\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:31,494][01000] Starting process inference_proc0-0\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:31,494][01000] Starting process rollout_proc0\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:31,494][01000] Starting process rollout_proc1\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:31,497][01000] Starting process rollout_proc2\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:31,497][01000] Starting process rollout_proc3\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:31,497][01000] Starting process rollout_proc4\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:31,497][01000] Starting process rollout_proc5\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:31,498][01000] Starting process rollout_proc6\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:31,498][01000] Starting process rollout_proc7\u001b[0m\n",
      "\u001b[37m\u001b[1m[2023-07-08 15:53:33,903][06934] InferenceWorker_p0-w0\tpid 6934\tparent 1000\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:33,912][06934] Using GPUs [0] for process 0 (actually maps to GPUs [0])\u001b[0m\n",
      "\u001b[37m\u001b[1m[2023-07-08 15:53:33,912][06934] Set environment var CUDA_VISIBLE_DEVICES to '0' (GPU indices [0]) for inference process 0\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:33,974][06934] Num visible devices: 1\u001b[0m\n",
      "\u001b[37m\u001b[1m[2023-07-08 15:53:34,039][06921] LearnerWorker_p0\tpid 6921\tparent 1000\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:34,072][06921] Using GPUs [0] for process 0 (actually maps to GPUs [0])\u001b[0m\n",
      "\u001b[37m\u001b[1m[2023-07-08 15:53:34,072][06921] Set environment var CUDA_VISIBLE_DEVICES to '0' (GPU indices [0]) for learning process 0\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:34,079][06937] Rollout worker 1 starting...\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:34,086][06921] Num visible devices: 1\u001b[0m\n",
      "\u001b[37m\u001b[1m[2023-07-08 15:53:34,101][06937] ROLLOUT worker 1\tpid 6937\tparent 1000\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:34,106][06937] Worker 1 uses CPU cores [1]\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:34,151][06944] Rollout worker 5 starting...\u001b[0m\n",
      "\u001b[37m\u001b[1m[2023-07-08 15:53:34,152][06944] ROLLOUT worker 5\tpid 6944\tparent 1000\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:34,152][06935] Rollout worker 0 starting...\u001b[0m\n",
      "\u001b[37m\u001b[1m[2023-07-08 15:53:34,152][06935] ROLLOUT worker 0\tpid 6935\tparent 1000\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:34,153][06944] Worker 5 uses CPU cores [1]\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:34,161][06935] Worker 0 uses CPU cores [0]\u001b[0m\n",
      "\u001b[37m\u001b[1m[2023-07-08 15:53:34,162][06921] Starting seed is not provided\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:34,162][06921] Using GPUs [0] for process 0 (actually maps to GPUs [0])\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:34,162][06921] Initializing actor-critic model on device cuda:0\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:34,162][06921] RunningMeanStd input shape: (3, 72, 128)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:34,163][06921] RunningMeanStd input shape: (1,)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:34,175][06936] Rollout worker 2 starting...\u001b[0m\n",
      "\u001b[37m\u001b[1m[2023-07-08 15:53:34,175][06936] ROLLOUT worker 2\tpid 6936\tparent 1000\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:34,177][06921] ConvEncoder: input_channels=3\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:34,191][06936] Worker 2 uses CPU cores [2]\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:34,275][06943] Rollout worker 6 starting...\u001b[0m\n",
      "\u001b[37m\u001b[1m[2023-07-08 15:53:34,275][06943] ROLLOUT worker 6\tpid 6943\tparent 1000\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:34,276][06943] Worker 6 uses CPU cores [2]\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:34,339][06945] Rollout worker 7 starting...\u001b[0m\n",
      "\u001b[37m\u001b[1m[2023-07-08 15:53:34,340][06945] ROLLOUT worker 7\tpid 6945\tparent 1000\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:34,351][06945] Worker 7 uses CPU cores [3]\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:34,365][06938] Rollout worker 4 starting...\u001b[0m\n",
      "\u001b[37m\u001b[1m[2023-07-08 15:53:34,365][06938] ROLLOUT worker 4\tpid 6938\tparent 1000\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:34,366][06938] Worker 4 uses CPU cores [0]\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:34,406][06939] Rollout worker 3 starting...\u001b[0m\n",
      "\u001b[37m\u001b[1m[2023-07-08 15:53:34,406][06939] ROLLOUT worker 3\tpid 6939\tparent 1000\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:34,407][06939] Worker 3 uses CPU cores [3]\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:34,589][06921] Conv encoder output size: 512\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:34,589][06921] Policy head output size: 512\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:34,596][06921] Created Actor Critic model with architecture:\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:34,596][06921] ActorCriticSharedWeights(\n",
      "  (obs_normalizer): ObservationNormalizer(\n",
      "    (running_mean_std): RunningMeanStdDictInPlace(\n",
      "      (running_mean_std): ModuleDict(\n",
      "        (obs): RunningMeanStdInPlace()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)\n",
      "  (encoder): VizdoomEncoder(\n",
      "    (basic_encoder): ConvEncoder(\n",
      "      (enc): RecursiveScriptModule(\n",
      "        original_name=ConvEncoderImpl\n",
      "        (conv_head): RecursiveScriptModule(\n",
      "          original_name=Sequential\n",
      "          (0): RecursiveScriptModule(original_name=Conv2d)\n",
      "          (1): RecursiveScriptModule(original_name=ELU)\n",
      "          (2): RecursiveScriptModule(original_name=Conv2d)\n",
      "          (3): RecursiveScriptModule(original_name=ELU)\n",
      "          (4): RecursiveScriptModule(original_name=Conv2d)\n",
      "          (5): RecursiveScriptModule(original_name=ELU)\n",
      "        )\n",
      "        (mlp_layers): RecursiveScriptModule(\n",
      "          original_name=Sequential\n",
      "          (0): RecursiveScriptModule(original_name=Linear)\n",
      "          (1): RecursiveScriptModule(original_name=ELU)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (core): ModelCoreRNN(\n",
      "    (core): GRU(512, 512)\n",
      "  )\n",
      "  (decoder): MlpDecoder(\n",
      "    (mlp): Identity()\n",
      "  )\n",
      "  (critic_linear): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (action_parameterization): ActionParameterizationDefault(\n",
      "    (distribution_linear): Linear(in_features=512, out_features=5, bias=True)\n",
      "  )\n",
      ")\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:36,106][06921] Using optimizer <class 'torch.optim.adam.Adam'>\u001b[0m\n",
      "\u001b[33m[2023-07-08 15:53:36,107][06921] No checkpoints found\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:36,107][06921] Did not load from checkpoint, starting from scratch!\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:36,107][06921] Initialized policy 0 weights for model version 0\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:36,109][06921] LearnerWorker_p0 finished initialization!\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:36,110][06921] Using GPUs [0] for process 0 (actually maps to GPUs [0])\u001b[0m\n",
      "\u001b[33m[2023-07-08 15:53:36,527][06934] Unhandled exception CUDA error: OS call failed or operation not supported on this OS\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      " in evt loop inference_proc0-0_evt_loop\u001b[0m\n",
      "Process inference_proc0-0:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/raj/repos/HF-DeepRL/8-Proximal-Policy-Optimization/envs/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/raj/repos/HF-DeepRL/8-Proximal-Policy-Optimization/envs/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/raj/repos/HF-DeepRL/8-Proximal-Policy-Optimization/envs/lib/python3.11/site-packages/signal_slot/signal_slot.py\", line 511, in _target\n",
      "    self.event_loop.exec()\n",
      "  File \"/home/raj/repos/HF-DeepRL/8-Proximal-Policy-Optimization/envs/lib/python3.11/site-packages/signal_slot/signal_slot.py\", line 403, in exec\n",
      "    raise exc\n",
      "  File \"/home/raj/repos/HF-DeepRL/8-Proximal-Policy-Optimization/envs/lib/python3.11/site-packages/signal_slot/signal_slot.py\", line 399, in exec\n",
      "    while self._loop_iteration():\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/raj/repos/HF-DeepRL/8-Proximal-Policy-Optimization/envs/lib/python3.11/site-packages/signal_slot/signal_slot.py\", line 372, in _loop_iteration\n",
      "    signals = self.signal_queue.get_many(timeout=closest_timer.remaining_time())\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"faster_fifo.pyx\", line 203, in faster_fifo.Queue.get_many\n",
      "  File \"faster_fifo.pyx\", line 223, in faster_fifo.Queue.get_many_nowait\n",
      "  File \"faster_fifo.pyx\", line 208, in faster_fifo.Queue.get_many\n",
      "  File \"faster_fifo.pyx\", line 242, in faster_fifo.Queue.parse_messages\n",
      "  File \"faster_fifo.pyx\", line 91, in faster_fifo.Queue.loads\n",
      "  File \"/home/raj/repos/HF-DeepRL/8-Proximal-Policy-Optimization/envs/lib/python3.11/site-packages/torch/multiprocessing/reductions.py\", line 121, in rebuild_cuda_tensor\n",
      "    storage = storage_cls._new_shared_cuda(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/raj/repos/HF-DeepRL/8-Proximal-Policy-Optimization/envs/lib/python3.11/site-packages/torch/storage.py\", line 955, in _new_shared_cuda\n",
      "    return torch.UntypedStorage._new_shared_cuda(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: OS call failed or operation not supported on this OS\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\u001b[36m[2023-07-08 15:53:39,378][01000] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 0. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:44,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:49,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[37m\u001b[1m[2023-07-08 15:53:51,421][01000] Heartbeat connected on Batcher_0\u001b[0m\n",
      "\u001b[37m\u001b[1m[2023-07-08 15:53:51,423][01000] Heartbeat connected on LearnerWorker_p0\u001b[0m\n",
      "\u001b[37m\u001b[1m[2023-07-08 15:53:51,430][01000] Heartbeat connected on RolloutWorker_w1\u001b[0m\n",
      "\u001b[37m\u001b[1m[2023-07-08 15:53:51,432][01000] Heartbeat connected on RolloutWorker_w2\u001b[0m\n",
      "\u001b[37m\u001b[1m[2023-07-08 15:53:51,434][01000] Heartbeat connected on RolloutWorker_w3\u001b[0m\n",
      "\u001b[37m\u001b[1m[2023-07-08 15:53:51,437][01000] Heartbeat connected on RolloutWorker_w5\u001b[0m\n",
      "\u001b[37m\u001b[1m[2023-07-08 15:53:51,438][01000] Heartbeat connected on RolloutWorker_w0\u001b[0m\n",
      "\u001b[37m\u001b[1m[2023-07-08 15:53:51,438][01000] Heartbeat connected on RolloutWorker_w4\u001b[0m\n",
      "\u001b[37m\u001b[1m[2023-07-08 15:53:51,439][01000] Heartbeat connected on RolloutWorker_w6\u001b[0m\n",
      "\u001b[37m\u001b[1m[2023-07-08 15:53:51,441][01000] Heartbeat connected on RolloutWorker_w7\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:54,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:53:59,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:54:04,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:54:09,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:54:14,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:54:19,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:54:24,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:54:29,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:54:34,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:54:39,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:54:44,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:54:49,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:54:54,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:54:59,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:55:04,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:55:09,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:55:14,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:55:19,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:55:24,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:55:29,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[37m\u001b[1m[2023-07-08 15:55:29,379][06921] Saving /home/raj/repos/HF-DeepRL/8-Proximal-Policy-Optimization/train_dir/default_experiment/checkpoint_p0/checkpoint_000000000_0.pth...\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:55:34,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:55:39,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:55:44,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:55:49,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:55:54,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:55:59,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:56:04,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:56:09,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:56:14,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:56:19,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:56:24,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:56:29,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:56:34,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:56:39,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:56:44,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:56:49,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:56:54,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:56:59,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:57:04,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:57:09,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:57:14,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:57:19,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:57:24,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:57:29,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[37m\u001b[1m[2023-07-08 15:57:29,379][06921] Saving /home/raj/repos/HF-DeepRL/8-Proximal-Policy-Optimization/train_dir/default_experiment/checkpoint_p0/checkpoint_000000000_0.pth...\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:57:34,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:57:39,377][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:57:44,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:57:49,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:57:54,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:57:59,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:58:04,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:58:09,378][01000] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)\u001b[0m\n",
      "\u001b[37m\u001b[1m[2023-07-08 15:58:13,740][01000] Keyboard interrupt detected in the event loop EvtLoop [Runner_EvtLoop, process=main process 1000], exiting...\u001b[0m\n",
      "\u001b[37m\u001b[1m[2023-07-08 15:58:13,741][01000] Runner profile tree view:\n",
      "main_loop: 282.3008\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:58:13,741][06939] Stopping RolloutWorker_w3...\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:58:13,742][06938] Stopping RolloutWorker_w4...\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:58:13,742][06921] Stopping Batcher_0...\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:58:13,742][06921] Loop batcher_evt_loop terminating...\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:58:13,742][06935] Stopping RolloutWorker_w0...\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:58:13,742][06935] Loop rollout_proc0_evt_loop terminating...\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:58:13,742][06945] Stopping RolloutWorker_w7...\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:58:13,742][06943] Stopping RolloutWorker_w6...\u001b[0m\n",
      "\u001b[37m\u001b[1m[2023-07-08 15:58:13,742][06921] Saving /home/raj/repos/HF-DeepRL/8-Proximal-Policy-Optimization/train_dir/default_experiment/checkpoint_p0/checkpoint_000000000_0.pth...\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:58:13,742][06939] Loop rollout_proc3_evt_loop terminating...\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:58:13,742][06945] Loop rollout_proc7_evt_loop terminating...\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:58:13,742][06936] Stopping RolloutWorker_w2...\u001b[0m\n",
      "\u001b[37m\u001b[1m[2023-07-08 15:58:13,743][01000] Collected {0: 0}, FPS: 0.0\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:58:13,743][06944] Stopping RolloutWorker_w5...\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:58:13,744][06936] Loop rollout_proc2_evt_loop terminating...\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:58:13,743][06943] Loop rollout_proc6_evt_loop terminating...\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:58:13,744][06944] Loop rollout_proc5_evt_loop terminating...\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:58:13,744][06937] Stopping RolloutWorker_w1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[2023-07-08 15:58:13,751][06937] Loop rollout_proc1_evt_loop terminating...\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:58:13,752][06938] Loop rollout_proc4_evt_loop terminating...\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:58:13,768][06921] Stopping LearnerWorker_p0...\u001b[0m\n",
      "\u001b[36m[2023-07-08 15:58:13,768][06921] Loop learner_proc0_evt_loop terminating...\u001b[0m\n",
      "[W CudaIPCTypes.cpp:15] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]\n"
     ]
    }
   ],
   "source": [
    "## Start the training, this should take around 15 minutes\n",
    "register_vizdoom_components()\n",
    "\n",
    "# The scenario we train on today is health gathering\n",
    "# other scenarios include \"doom_basic\", \"doom_two_colors_easy\", \"doom_dm\", \"doom_dwango5\", \"doom_my_way_home\", \"doom_deadly_corridor\", \"doom_defend_the_center\", \"doom_defend_the_line\"\n",
    "env = \"doom_health_gathering_supreme\"\n",
    "cfg = parse_vizdoom_cfg(\n",
    "    argv=[f\"--env={env}\", \"--num_workers=8\", \"--num_envs_per_worker=4\", \"--train_for_env_steps=4000000\"]\n",
    ")\n",
    "\n",
    "status = run_rl(cfg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
