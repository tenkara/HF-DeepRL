{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ml-agents'...\n",
      "remote: Enumerating objects: 90265, done.\u001b[K\n",
      "remote: Counting objects: 100% (1161/1161), done.\u001b[K\n",
      "remote: Compressing objects: 100% (521/521), done.\u001b[K\n",
      "remote: Total 90265 (delta 665), reused 971 (delta 571), pack-reused 89104\u001b[K\n",
      "Receiving objects: 100% (90265/90265), 2.87 GiB | 10.96 MiB/s, done.\n",
      "Resolving deltas: 100% (65796/65796), done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/Unity-Technologies/ml-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/raj/repos/HF-DeepRL/7-Multi-Agents-AI-vs-AI/ml-agents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/raj/repos/HF-DeepRL/7-Multi-Agents-AI-vs-AI/ml-agents/ml-agents-envs\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: cloudpickle in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from mlagents-envs==0.31.0.dev0) (2.2.1)\n",
      "Requirement already satisfied: grpcio>=1.11.0 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from mlagents-envs==0.31.0.dev0) (1.56.0)\n",
      "Requirement already satisfied: Pillow>=4.2.1 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from mlagents-envs==0.31.0.dev0) (10.0.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.6 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from mlagents-envs==0.31.0.dev0) (3.19.6)\n",
      "Requirement already satisfied: pyyaml>=3.1.0 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from mlagents-envs==0.31.0.dev0) (6.0)\n",
      "Requirement already satisfied: gym>=0.21.0 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from mlagents-envs==0.31.0.dev0) (0.26.2)\n",
      "Requirement already satisfied: pettingzoo==1.15.0 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from mlagents-envs==0.31.0.dev0) (1.15.0)\n",
      "Requirement already satisfied: numpy==1.21.2 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from mlagents-envs==0.31.0.dev0) (1.21.2)\n",
      "Requirement already satisfied: filelock>=3.4.0 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from mlagents-envs==0.31.0.dev0) (3.12.2)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from gym>=0.21.0->mlagents-envs==0.31.0.dev0) (0.0.8)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from gym>=0.21.0->mlagents-envs==0.31.0.dev0) (6.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from importlib-metadata>=4.8.0->gym>=0.21.0->mlagents-envs==0.31.0.dev0) (3.15.0)\n",
      "Installing collected packages: mlagents-envs\n",
      "  Attempting uninstall: mlagents-envs\n",
      "    Found existing installation: mlagents-envs 0.31.0.dev0\n",
      "    Uninstalling mlagents-envs-0.31.0.dev0:\n",
      "      Successfully uninstalled mlagents-envs-0.31.0.dev0\n",
      "  Running setup.py develop for mlagents-envs\n",
      "Successfully installed mlagents-envs-0.31.0.dev0\n",
      "Obtaining file:///home/raj/repos/HF-DeepRL/7-Multi-Agents-AI-vs-AI/ml-agents/ml-agents\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: grpcio>=1.11.0 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from mlagents==0.31.0.dev0) (1.56.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from mlagents==0.31.0.dev0) (3.9.0)\n",
      "Requirement already satisfied: mlagents_envs==0.31.0.dev0 in ./ml-agents-envs (from mlagents==0.31.0.dev0) (0.31.0.dev0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.13.3 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from mlagents==0.31.0.dev0) (1.21.2)\n",
      "Requirement already satisfied: Pillow>=4.2.1 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from mlagents==0.31.0.dev0) (10.0.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.6 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from mlagents==0.31.0.dev0) (3.19.6)\n",
      "Requirement already satisfied: pyyaml>=3.1.0 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from mlagents==0.31.0.dev0) (6.0)\n",
      "Requirement already satisfied: tensorboard>=1.15 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from mlagents==0.31.0.dev0) (2.13.0)\n",
      "Requirement already satisfied: attrs>=19.3.0 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from mlagents==0.31.0.dev0) (23.1.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.14 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from mlagents==0.31.0.dev0) (0.16.2)\n",
      "Requirement already satisfied: torch<=1.11.0,>=1.8.0 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from mlagents==0.31.0.dev0) (1.11.0)\n",
      "Requirement already satisfied: cattrs<1.7,>=1.1.0 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from mlagents==0.31.0.dev0) (1.5.0)\n",
      "Requirement already satisfied: cloudpickle in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from mlagents_envs==0.31.0.dev0->mlagents==0.31.0.dev0) (2.2.1)\n",
      "Requirement already satisfied: gym>=0.21.0 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from mlagents_envs==0.31.0.dev0->mlagents==0.31.0.dev0) (0.26.2)\n",
      "Requirement already satisfied: pettingzoo==1.15.0 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from mlagents_envs==0.31.0.dev0->mlagents==0.31.0.dev0) (1.15.0)\n",
      "Requirement already satisfied: filelock>=3.4.0 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from mlagents_envs==0.31.0.dev0->mlagents==0.31.0.dev0) (3.12.2)\n",
      "Requirement already satisfied: fsspec in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from huggingface_hub>=0.14->mlagents==0.31.0.dev0) (2023.6.0)\n",
      "Requirement already satisfied: requests in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from huggingface_hub>=0.14->mlagents==0.31.0.dev0) (2.29.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from huggingface_hub>=0.14->mlagents==0.31.0.dev0) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from huggingface_hub>=0.14->mlagents==0.31.0.dev0) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from huggingface_hub>=0.14->mlagents==0.31.0.dev0) (23.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from tensorboard>=1.15->mlagents==0.31.0.dev0) (1.4.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from tensorboard>=1.15->mlagents==0.31.0.dev0) (2.21.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from tensorboard>=1.15->mlagents==0.31.0.dev0) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from tensorboard>=1.15->mlagents==0.31.0.dev0) (3.4.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from tensorboard>=1.15->mlagents==0.31.0.dev0) (67.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from tensorboard>=1.15->mlagents==0.31.0.dev0) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from tensorboard>=1.15->mlagents==0.31.0.dev0) (2.3.6)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from tensorboard>=1.15->mlagents==0.31.0.dev0) (0.38.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15->mlagents==0.31.0.dev0) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15->mlagents==0.31.0.dev0) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15->mlagents==0.31.0.dev0) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15->mlagents==0.31.0.dev0) (1.16.0)\n",
      "Requirement already satisfied: urllib3<2.0 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15->mlagents==0.31.0.dev0) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=1.15->mlagents==0.31.0.dev0) (1.3.1)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from gym>=0.21.0->mlagents_envs==0.31.0.dev0->mlagents==0.31.0.dev0) (0.0.8)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from gym>=0.21.0->mlagents_envs==0.31.0.dev0->mlagents==0.31.0.dev0) (6.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from requests->huggingface_hub>=0.14->mlagents==0.31.0.dev0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from requests->huggingface_hub>=0.14->mlagents==0.31.0.dev0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from requests->huggingface_hub>=0.14->mlagents==0.31.0.dev0) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard>=1.15->mlagents==0.31.0.dev0) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from importlib-metadata>=4.8.0->gym>=0.21.0->mlagents_envs==0.31.0.dev0->mlagents==0.31.0.dev0) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.15->mlagents==0.31.0.dev0) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=1.15->mlagents==0.31.0.dev0) (3.2.2)\n",
      "Installing collected packages: mlagents\n",
      "  Attempting uninstall: mlagents\n",
      "    Found existing installation: mlagents 0.31.0.dev0\n",
      "    Uninstalling mlagents-0.31.0.dev0:\n",
      "      Successfully uninstalled mlagents-0.31.0.dev0\n",
      "  Running setup.py develop for mlagents\n",
      "Successfully installed mlagents-0.31.0.dev0\n"
     ]
    }
   ],
   "source": [
    "%cd ml-agents\n",
    "! pip install -e ./ml-agents-envs\n",
    "! pip install -e ./ml-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (1.11.0)\n",
      "Requirement already satisfied: typing-extensions in /home/raj/anaconda3/envs/rl/lib/python3.9/site-packages (from torch) (4.7.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir ./training-envs-executables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod -R 755 ./training-envs-executables/SoccerTwos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            ┐  ╖\n",
      "        ╓╖╬│╡  ││╬╖╖\n",
      "    ╓╖╬│││││┘  ╬│││││╬╖\n",
      " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
      " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
      " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
      " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
      " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
      " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
      " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
      "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
      "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
      "          ╙╬╬╬╣╣╣╜\n",
      "             ╙\n",
      "        \n",
      " Version information:\n",
      "  ml-agents: 0.31.0.dev0,\n",
      "  ml-agents-envs: 0.31.0.dev0,\n",
      "  Communicator API: 1.5.0,\n",
      "  PyTorch: 2.0.1\n",
      "[INFO] Connected to Unity environment with package version 2.3.0-exp.3 and communication version 1.5.0\n",
      "[INFO] Connected new brain: SoccerTwos?team=1\n",
      "[INFO] Connected new brain: SoccerTwos?team=0\n",
      "[INFO] Hyperparameters for behavior name SoccerTwos: \n",
      "\ttrainer_type:\tpoca\n",
      "\thyperparameters:\t\n",
      "\t  batch_size:\t2048\n",
      "\t  buffer_size:\t20480\n",
      "\t  learning_rate:\t0.0003\n",
      "\t  beta:\t0.005\n",
      "\t  epsilon:\t0.2\n",
      "\t  lambd:\t0.95\n",
      "\t  num_epoch:\t3\n",
      "\t  learning_rate_schedule:\tconstant\n",
      "\t  beta_schedule:\tconstant\n",
      "\t  epsilon_schedule:\tconstant\n",
      "\tcheckpoint_interval:\t500000\n",
      "\tnetwork_settings:\t\n",
      "\t  normalize:\tFalse\n",
      "\t  hidden_units:\t512\n",
      "\t  num_layers:\t3\n",
      "\t  vis_encode_type:\tsimple\n",
      "\t  memory:\tNone\n",
      "\t  goal_conditioning_type:\thyper\n",
      "\t  deterministic:\tFalse\n",
      "\treward_signals:\t\n",
      "\t  extrinsic:\t\n",
      "\t    gamma:\t0.99\n",
      "\t    strength:\t1.0\n",
      "\t    network_settings:\t\n",
      "\t      normalize:\tFalse\n",
      "\t      hidden_units:\t128\n",
      "\t      num_layers:\t2\n",
      "\t      vis_encode_type:\tsimple\n",
      "\t      memory:\tNone\n",
      "\t      goal_conditioning_type:\thyper\n",
      "\t      deterministic:\tFalse\n",
      "\tinit_path:\tNone\n",
      "\tkeep_checkpoints:\t5\n",
      "\teven_checkpoints:\tFalse\n",
      "\tmax_steps:\t2000000\n",
      "\ttime_horizon:\t1000\n",
      "\tsummary_freq:\t10000\n",
      "\tthreaded:\tFalse\n",
      "\tself_play:\t\n",
      "\t  save_steps:\t50000\n",
      "\t  team_change:\t350000\n",
      "\t  swap_steps:\t50000\n",
      "\t  window:\t30\n",
      "\t  play_against_latest_model_ratio:\t0.5\n",
      "\t  initial_elo:\t1200.0\n",
      "\tbehavioral_cloning:\tNone\n",
      "[INFO] Resuming from results/SoccerTwos/SoccerTwos.\n",
      "[INFO] Resuming training from step 1000068.\n",
      "/home/raj/repos/HF-DeepRL/7-Multi-Agents-AI-vs-AI/ml-agents/ml-agents/mlagents/trainers/torch_entities/utils.py:289: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/TensorShape.cpp:3571.)\n",
      "  torch.nn.functional.one_hot(_act.T, action_size[i]).float()\n",
      "[INFO] SoccerTwos. Step: 1010000. Time Elapsed: 16.196 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] SoccerTwos. Step: 1020000. Time Elapsed: 33.224 s. Mean Reward: 0.000. Mean Group Reward: -0.308. Training. ELO: 1193.533.\n",
      "[INFO] SoccerTwos. Step: 1030000. Time Elapsed: 38.584 s. Mean Reward: 0.000. Mean Group Reward: 0.163. Training. ELO: 1193.533.\n",
      "[INFO] SoccerTwos. Step: 1040000. Time Elapsed: 53.690 s. Mean Reward: 0.000. Mean Group Reward: -0.170. Training. ELO: 1193.533.\n",
      "[INFO] SoccerTwos. Step: 1050000. Time Elapsed: 67.406 s. Mean Reward: 0.000. Mean Group Reward: -0.308. Training. ELO: 1193.533.\n",
      "[INFO] SoccerTwos. Step: 1060000. Time Elapsed: 74.079 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] SoccerTwos. Step: 1070000. Time Elapsed: 89.994 s. Mean Reward: 0.000. Mean Group Reward: -0.329. Training. ELO: 1192.664.\n",
      "[INFO] SoccerTwos. Step: 1080000. Time Elapsed: 98.302 s. Mean Reward: 0.000. Mean Group Reward: -0.024. Training. ELO: 1191.575.\n",
      "[INFO] SoccerTwos. Step: 1090000. Time Elapsed: 111.205 s. Mean Reward: 0.000. Mean Group Reward: -0.100. Training.\n",
      "[INFO] SoccerTwos. Step: 1100000. Time Elapsed: 128.362 s. Mean Reward: 0.000. Mean Group Reward: 0.032. Training. ELO: 1192.191.\n",
      "[INFO] SoccerTwos. Step: 1110000. Time Elapsed: 132.609 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] SoccerTwos. Step: 1120000. Time Elapsed: 149.685 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] SoccerTwos. Step: 1130000. Time Elapsed: 161.178 s. Mean Reward: 0.000. Mean Group Reward: 0.135. Training. ELO: 1192.618.\n",
      "[INFO] SoccerTwos. Step: 1140000. Time Elapsed: 170.154 s. Mean Reward: 0.000. Mean Group Reward: -0.133. Training. ELO: 1192.618.\n",
      "[INFO] SoccerTwos. Step: 1150000. Time Elapsed: 183.901 s. Mean Reward: 0.000. Mean Group Reward: -0.333. Training. ELO: 1192.618.\n",
      "[INFO] SoccerTwos. Step: 1160000. Time Elapsed: 196.767 s. Mean Reward: 0.000. Mean Group Reward: -0.285. Training. ELO: 1191.255.\n",
      "[INFO] SoccerTwos. Step: 1170000. Time Elapsed: 210.967 s. Mean Reward: 0.000. Mean Group Reward: -0.273. Training. ELO: 1189.903.\n",
      "[INFO] SoccerTwos. Step: 1180000. Time Elapsed: 220.120 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] SoccerTwos. Step: 1190000. Time Elapsed: 233.586 s. Mean Reward: 0.000. Mean Group Reward: 0.187. Training. ELO: 1190.925.\n",
      "[INFO] SoccerTwos. Step: 1200000. Time Elapsed: 243.249 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] SoccerTwos. Step: 1210000. Time Elapsed: 253.736 s. Mean Reward: 0.000. Mean Group Reward: -0.154. Training. ELO: 1191.192.\n",
      "[INFO] SoccerTwos. Step: 1220000. Time Elapsed: 269.531 s. Mean Reward: 0.000. Mean Group Reward: -0.071. Training. ELO: 1193.074.\n",
      "[INFO] SoccerTwos. Step: 1230000. Time Elapsed: 276.763 s. Mean Reward: 0.000. Mean Group Reward: 0.059. Training.\n",
      "[INFO] SoccerTwos. Step: 1240000. Time Elapsed: 291.256 s. Mean Reward: 0.000. Mean Group Reward: -0.169. Training. ELO: 1193.104.\n",
      "[INFO] SoccerTwos. Step: 1250000. Time Elapsed: 304.148 s. Mean Reward: 0.000. Mean Group Reward: -0.309. Training. ELO: 1192.679.\n",
      "[INFO] SoccerTwos. Step: 1260000. Time Elapsed: 318.162 s. Mean Reward: 0.000. Mean Group Reward: -0.131. Training. ELO: 1191.932.\n",
      "[INFO] SoccerTwos. Step: 1270000. Time Elapsed: 328.217 s. Mean Reward: 0.000. Mean Group Reward: -0.500. Training. ELO: 1191.682.\n",
      "[INFO] SoccerTwos. Step: 1280000. Time Elapsed: 342.328 s. Mean Reward: 0.000. Mean Group Reward: 0.013. Training. ELO: 1191.682.\n",
      "[INFO] SoccerTwos. Step: 1290000. Time Elapsed: 351.531 s. Mean Reward: 0.000. Mean Group Reward: -0.091. Training. ELO: 1191.682.\n",
      "[INFO] SoccerTwos. Step: 1300000. Time Elapsed: 364.260 s. Mean Reward: 0.000. Mean Group Reward: -0.198. Training. ELO: 1191.682.\n",
      "[INFO] SoccerTwos. Step: 1310000. Time Elapsed: 381.828 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] SoccerTwos. Step: 1320000. Time Elapsed: 388.260 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] SoccerTwos. Step: 1330000. Time Elapsed: 403.391 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] SoccerTwos. Step: 1340000. Time Elapsed: 412.109 s. Mean Reward: 0.000. Mean Group Reward: 0.141. Training. ELO: 1191.682.\n",
      "[INFO] SoccerTwos. Step: 1350000. Time Elapsed: 425.208 s. Mean Reward: 0.000. Mean Group Reward: -0.182. Training. ELO: 1191.682.\n",
      "[INFO] SoccerTwos. Step: 1360000. Time Elapsed: 444.487 s. Mean Reward: 0.000. Mean Group Reward: 0.070. Training. ELO: 1192.438.\n",
      "[INFO] SoccerTwos. Step: 1370000. Time Elapsed: 455.753 s. Mean Reward: 0.000. Mean Group Reward: -0.182. Training. ELO: 1191.941.\n",
      "[INFO] SoccerTwos. Step: 1380000. Time Elapsed: 466.724 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] SoccerTwos. Step: 1390000. Time Elapsed: 481.232 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] SoccerTwos. Step: 1400000. Time Elapsed: 489.345 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] SoccerTwos. Step: 1410000. Time Elapsed: 502.332 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] SoccerTwos. Step: 1420000. Time Elapsed: 520.016 s. Mean Reward: 0.000. Mean Group Reward: -0.462. Training. ELO: 1189.832.\n",
      "[INFO] SoccerTwos. Step: 1430000. Time Elapsed: 525.406 s. Mean Reward: 0.000. Mean Group Reward: 0.060. Training.\n",
      "[INFO] SoccerTwos. Step: 1440000. Time Elapsed: 540.780 s. Mean Reward: 0.000. Mean Group Reward: -0.182. Training. ELO: 1189.246.\n",
      "[INFO] SoccerTwos. Step: 1450000. Time Elapsed: 549.061 s. Mean Reward: 0.000. Mean Group Reward: -0.186. Training. ELO: 1189.017.\n",
      "[INFO] SoccerTwos. Step: 1460000. Time Elapsed: 561.787 s. Mean Reward: 0.000. Mean Group Reward: 0.103. Training. ELO: 1189.532.\n",
      "[INFO] SoccerTwos. Step: 1470000. Time Elapsed: 577.136 s. Mean Reward: 0.000. Mean Group Reward: 0.060. Training. ELO: 1189.786.\n",
      "[INFO] SoccerTwos. Step: 1480000. Time Elapsed: 585.644 s. Mean Reward: 0.000. Mean Group Reward: -0.093. Training. ELO: 1189.786.\n",
      "[INFO] SoccerTwos. Step: 1490000. Time Elapsed: 598.299 s. Mean Reward: 0.000. Mean Group Reward: 0.123. Training. ELO: 1189.786.\n",
      "[INFO] SoccerTwos. Step: 1500000. Time Elapsed: 609.756 s. Mean Reward: 0.000. Mean Group Reward: -0.182. Training. ELO: 1189.786.\n",
      "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "[INFO] Exported results/SoccerTwos/SoccerTwos/SoccerTwos-1499278.onnx\n",
      "[INFO] SoccerTwos. Step: 1510000. Time Elapsed: 625.500 s. Mean Reward: 0.000. Mean Group Reward: 0.047. Training. ELO: 1189.786.\n",
      "[INFO] SoccerTwos. Step: 1520000. Time Elapsed: 634.888 s. Mean Reward: 0.000. Mean Group Reward: -0.252. Training. ELO: 1189.225.\n",
      "[INFO] SoccerTwos. Step: 1530000. Time Elapsed: 649.019 s. Mean Reward: 0.000. Mean Group Reward: -0.200. Training. ELO: 1188.088.\n",
      "[INFO] SoccerTwos. Step: 1540000. Time Elapsed: 661.290 s. Mean Reward: 0.000. Mean Group Reward: -0.167. Training. ELO: 1187.110.\n",
      "[INFO] SoccerTwos. Step: 1550000. Time Elapsed: 671.059 s. Mean Reward: 0.000. Mean Group Reward: 0.154. Training. ELO: 1188.147.\n",
      "[INFO] SoccerTwos. Step: 1560000. Time Elapsed: 681.578 s. Mean Reward: 0.000. Mean Group Reward: -0.402. Training. ELO: 1187.087.\n",
      "[INFO] SoccerTwos. Step: 1570000. Time Elapsed: 696.878 s. Mean Reward: 0.000. Mean Group Reward: -0.200. Training. ELO: 1185.314.\n",
      "[INFO] SoccerTwos. Step: 1580000. Time Elapsed: 708.196 s. Mean Reward: 0.000. Mean Group Reward: 0.145. Training. ELO: 1185.840.\n",
      "[INFO] SoccerTwos. Step: 1590000. Time Elapsed: 720.799 s. Mean Reward: 0.000. Mean Group Reward: 0.021. Training. ELO: 1186.861.\n",
      "[INFO] SoccerTwos. Step: 1600000. Time Elapsed: 728.794 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] SoccerTwos. Step: 1610000. Time Elapsed: 746.182 s. Mean Reward: 0.000. Mean Group Reward: 0.226. Training. ELO: 1188.891.\n",
      "[INFO] SoccerTwos. Step: 1620000. Time Elapsed: 756.727 s. Mean Reward: 0.000. Mean Group Reward: 0.127. Training. ELO: 1191.411.\n",
      "[INFO] SoccerTwos. Step: 1630000. Time Elapsed: 767.627 s. Mean Reward: 0.000. Mean Group Reward: -0.200. Training.\n",
      "[INFO] SoccerTwos. Step: 1640000. Time Elapsed: 779.042 s. Mean Reward: 0.000. Mean Group Reward: 0.152. Training. ELO: 1191.908.\n",
      "[INFO] SoccerTwos. Step: 1650000. Time Elapsed: 791.929 s. Mean Reward: 0.000. Mean Group Reward: -0.005. Training. ELO: 1192.228.\n",
      "[INFO] SoccerTwos. Step: 1660000. Time Elapsed: 807.368 s. Mean Reward: 0.000. Mean Group Reward: -0.287. Training. ELO: 1190.145.\n",
      "[INFO] SoccerTwos. Step: 1670000. Time Elapsed: 814.332 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] SoccerTwos. Step: 1680000. Time Elapsed: 827.493 s. Mean Reward: 0.000. Mean Group Reward: -0.110. Training. ELO: 1190.634.\n",
      "[INFO] SoccerTwos. Step: 1690000. Time Elapsed: 842.603 s. Mean Reward: 0.000. Mean Group Reward: 0.006. Training. ELO: 1192.355.\n",
      "[INFO] SoccerTwos. Step: 1700000. Time Elapsed: 854.135 s. Mean Reward: 0.000. Mean Group Reward: 0.124. Training. ELO: 1193.310.\n",
      "[INFO] SoccerTwos. Step: 1710000. Time Elapsed: 867.698 s. Mean Reward: 0.000. Mean Group Reward: -0.160. Training. ELO: 1194.044.\n",
      "[INFO] SoccerTwos. Step: 1720000. Time Elapsed: 884.588 s. Mean Reward: 0.000. Mean Group Reward: 0.035. Training. ELO: 1194.044.\n",
      "[INFO] SoccerTwos. Step: 1730000. Time Elapsed: 893.491 s. Mean Reward: 0.000. Mean Group Reward: -0.170. Training. ELO: 1194.044.\n",
      "[INFO] SoccerTwos. Step: 1740000. Time Elapsed: 911.968 s. Mean Reward: 0.000. Mean Group Reward: 0.043. Training. ELO: 1194.044.\n",
      "[INFO] SoccerTwos. Step: 1750000. Time Elapsed: 918.488 s. Mean Reward: 0.000. Mean Group Reward: -0.429. Training. ELO: 1194.044.\n",
      "[INFO] SoccerTwos. Step: 1760000. Time Elapsed: 930.147 s. Mean Reward: 0.000. Mean Group Reward: 0.107. Training. ELO: 1194.935.\n",
      "[INFO] SoccerTwos. Step: 1770000. Time Elapsed: 944.646 s. Mean Reward: 0.000. Mean Group Reward: -0.101. Training. ELO: 1195.444.\n",
      "[INFO] SoccerTwos. Step: 1780000. Time Elapsed: 956.290 s. Mean Reward: 0.000. Mean Group Reward: 0.207. Training. ELO: 1197.131.\n",
      "[INFO] SoccerTwos. Step: 1790000. Time Elapsed: 969.097 s. Mean Reward: 0.000. Mean Group Reward: -0.402. Training. ELO: 1196.872.\n",
      "[INFO] SoccerTwos. Step: 1800000. Time Elapsed: 984.096 s. Mean Reward: 0.000. Mean Group Reward: -0.182. Training. ELO: 1194.987.\n",
      "[INFO] SoccerTwos. Step: 1810000. Time Elapsed: 991.508 s. Mean Reward: 0.000. Mean Group Reward: 0.000. Training. ELO: 1193.971.\n",
      "[INFO] SoccerTwos. Step: 1820000. Time Elapsed: 1006.850 s. Mean Reward: 0.000. Mean Group Reward: -0.192. Training. ELO: 1193.697.\n",
      "[INFO] SoccerTwos. Step: 1830000. Time Elapsed: 1017.184 s. Mean Reward: 0.000. Mean Group Reward: 0.098. Training. ELO: 1193.579.\n",
      "[INFO] SoccerTwos. Step: 1840000. Time Elapsed: 1029.195 s. Mean Reward: 0.000. Mean Group Reward: -0.154. Training. ELO: 1195.128.\n",
      "[INFO] SoccerTwos. Step: 1850000. Time Elapsed: 1039.558 s. Mean Reward: 0.000. Mean Group Reward: 0.027. Training. ELO: 1195.091.\n",
      "[INFO] SoccerTwos. Step: 1860000. Time Elapsed: 1054.323 s. Mean Reward: 0.000. Mean Group Reward: -0.100. Training.\n",
      "[INFO] SoccerTwos. Step: 1870000. Time Elapsed: 1068.933 s. Mean Reward: 0.000. Mean Group Reward: 0.031. Training. ELO: 1194.577.\n",
      "[INFO] SoccerTwos. Step: 1880000. Time Elapsed: 1076.182 s. Mean Reward: 0.000. Mean Group Reward: 0.152. Training. ELO: 1194.577.\n",
      "[INFO] SoccerTwos. Step: 1890000. Time Elapsed: 1091.296 s. Mean Reward: 0.000. Mean Group Reward: 0.060. Training. ELO: 1194.577.\n",
      "[INFO] SoccerTwos. Step: 1900000. Time Elapsed: 1103.802 s. Mean Reward: 0.000. Mean Group Reward: -0.250. Training. ELO: 1194.577.\n",
      "[INFO] SoccerTwos. Step: 1910000. Time Elapsed: 1114.471 s. Mean Reward: 0.000. Mean Group Reward: -0.295. Training. ELO: 1194.900.\n",
      "[INFO] SoccerTwos. Step: 1920000. Time Elapsed: 1127.856 s. Mean Reward: 0.000. Mean Group Reward: -0.074. Training. ELO: 1195.036.\n",
      "[INFO] SoccerTwos. Step: 1930000. Time Elapsed: 1136.179 s. Mean Reward: 0.000. Mean Group Reward: -0.167. Training. ELO: 1194.017.\n",
      "[INFO] SoccerTwos. Step: 1940000. Time Elapsed: 1149.162 s. Mean Reward: 0.000. Mean Group Reward: 0.197. Training. ELO: 1195.428.\n",
      "[INFO] SoccerTwos. Step: 1950000. Time Elapsed: 1162.466 s. Mean Reward: 0.000. Mean Group Reward: -0.500. Training. ELO: 1193.674.\n",
      "[INFO] SoccerTwos. Step: 1960000. Time Elapsed: 1173.341 s. Mean Reward: 0.000. Mean Group Reward: 0.022. Training. ELO: 1192.419.\n",
      "[INFO] SoccerTwos. Step: 1970000. Time Elapsed: 1186.725 s. Mean Reward: 0.000. Mean Group Reward: -0.408. Training. ELO: 1192.419.\n",
      "[INFO] SoccerTwos. Step: 1980000. Time Elapsed: 1200.663 s. Mean Reward: 0.000. Mean Group Reward: -0.167. Training. ELO: 1192.419.\n",
      "[INFO] SoccerTwos. Step: 1990000. Time Elapsed: 1209.759 s. Mean Reward: 0.000. Mean Group Reward: -0.200. Training. ELO: 1192.419.\n",
      "[INFO] SoccerTwos. Step: 2000000. Time Elapsed: 1223.660 s. Mean Reward: 0.000. Mean Group Reward: -0.382. Training. ELO: 1192.419.\n",
      "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "[INFO] Exported results/SoccerTwos/SoccerTwos/SoccerTwos-1999720.onnx\n",
      "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "[INFO] Exported results/SoccerTwos/SoccerTwos/SoccerTwos-2000720.onnx\n",
      "[INFO] Copied results/SoccerTwos/SoccerTwos/SoccerTwos-2000720.onnx to results/SoccerTwos/SoccerTwos.onnx.\n"
     ]
    }
   ],
   "source": [
    "! mlagents-learn ./config/poca/SoccerTwos.yaml --env=./training-envs-executables/SoccerTwos/SoccerTwos.x86_64 --run-id=\"SoccerTwos\" --no-graphics --resume"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
