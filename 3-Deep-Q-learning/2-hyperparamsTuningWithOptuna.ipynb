{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning with Optuna\n",
    "\n",
    "Github repo: https://github.com/araffin/tools-for-robotic-rl-icra2022\n",
    "\n",
    "Optuna: https://github.com/optuna/optuna\n",
    "\n",
    "Stable-Baselines3: https://github.com/DLR-RM/stable-baselines3\n",
    "\n",
    "Documentation: https://stable-baselines3.readthedocs.io/en/master/\n",
    "\n",
    "SB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\n",
    "\n",
    "RL Baselines3 zoo: https://github.com/DLR-RM/rl-baselines3-zoo\n",
    "\n",
    "[RL Baselines3 Zoo](https://github.com/DLR-RM/rl-baselines3-zoo) is a collection of pre-trained Reinforcement Learning agents using Stable-Baselines3.\n",
    "\n",
    "It also provides basic scripts for training, evaluating agents, tuning hyperparameters and recording videos.\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, you will learn the importance of tuning hyperparameters. You will first try to optimize the parameters manually and then we will see how to automate the search using Optuna.\n",
    "\n",
    "\n",
    "## Install Dependencies and Stable Baselines3 Using Pip\n",
    "\n",
    "List of full dependencies can be found in the [README](https://github.com/DLR-RM/stable-baselines3).\n",
    "\n",
    "\n",
    "```\n",
    "pip install stable-baselines3[extra]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3[extra] in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (2.0.0)\n",
      "Requirement already satisfied: pandas in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from stable-baselines3[extra]) (2.0.3)\n",
      "Requirement already satisfied: gymnasium==0.28.1 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from stable-baselines3[extra]) (0.28.1)\n",
      "Requirement already satisfied: matplotlib in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from stable-baselines3[extra]) (3.7.1)\n",
      "Requirement already satisfied: torch>=1.11 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from stable-baselines3[extra]) (1.11.0+cu113)\n",
      "Requirement already satisfied: cloudpickle in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from stable-baselines3[extra]) (2.2.1)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from stable-baselines3[extra]) (1.21.2)\n",
      "Requirement already satisfied: psutil in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from stable-baselines3[extra]) (5.9.5)\n",
      "Requirement already satisfied: rich in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from stable-baselines3[extra]) (13.4.2)\n",
      "Requirement already satisfied: pillow in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from stable-baselines3[extra]) (10.0.0)\n",
      "Requirement already satisfied: tqdm in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from stable-baselines3[extra]) (4.65.0)\n",
      "Requirement already satisfied: opencv-python in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from stable-baselines3[extra]) (4.8.0.74)\n",
      "Requirement already satisfied: shimmy[atari]~=0.2.1 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from stable-baselines3[extra]) (0.2.1)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from stable-baselines3[extra]) (2.13.0)\n",
      "Collecting autorom[accept-rom-license]~=0.6.0\n",
      "  Downloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
      "Requirement already satisfied: pygame in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from stable-baselines3[extra]) (2.1.3)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from gymnasium==0.28.1->stable-baselines3[extra]) (4.7.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from gymnasium==0.28.1->stable-baselines3[extra]) (0.0.4)\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from gymnasium==0.28.1->stable-baselines3[extra]) (1.0.0)\n",
      "Requirement already satisfied: requests in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (2.31.0)\n",
      "Requirement already satisfied: click in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (8.1.3)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: ale-py~=0.8.1 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from shimmy[atari]~=0.2.1->stable-baselines3[extra]) (0.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.21.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.1)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.19.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.3.6)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.40.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.4.3)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.56.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (59.6.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from matplotlib->stable-baselines3[extra]) (1.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from matplotlib->stable-baselines3[extra]) (3.1.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from matplotlib->stable-baselines3[extra]) (4.40.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from matplotlib->stable-baselines3[extra]) (23.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from matplotlib->stable-baselines3[extra]) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from matplotlib->stable-baselines3[extra]) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from pandas->stable-baselines3[extra]) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from pandas->stable-baselines3[extra]) (2023.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from rich->stable-baselines3[extra]) (2.15.1)\n",
      "Requirement already satisfied: importlib-resources in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from ale-py~=0.8.1->shimmy[atari]~=0.2.1->stable-baselines3[extra]) (5.12.0)\n",
      "Requirement already satisfied: urllib3<2.0 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (1.26.16)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (5.3.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from requests->autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from requests->autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from requests->autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (3.2.2)\n",
      "Installing collected packages: autorom\n",
      "  Attempting uninstall: autorom\n",
      "    Found existing installation: AutoROM 0.4.2\n",
      "    Uninstalling AutoROM-0.4.2:\n",
      "      Successfully uninstalled AutoROM-0.4.2\n",
      "Successfully installed autorom-0.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sb3-contrib in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (2.0.0)\n",
      "Requirement already satisfied: stable-baselines3>=2.0.0 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from sb3-contrib) (2.0.0)\n",
      "Requirement already satisfied: pandas in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from stable-baselines3>=2.0.0->sb3-contrib) (2.0.3)\n",
      "Requirement already satisfied: cloudpickle in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from stable-baselines3>=2.0.0->sb3-contrib) (2.2.1)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from stable-baselines3>=2.0.0->sb3-contrib) (1.21.2)\n",
      "Requirement already satisfied: gymnasium==0.28.1 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from stable-baselines3>=2.0.0->sb3-contrib) (0.28.1)\n",
      "Requirement already satisfied: matplotlib in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from stable-baselines3>=2.0.0->sb3-contrib) (3.7.1)\n",
      "Requirement already satisfied: torch>=1.11 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from stable-baselines3>=2.0.0->sb3-contrib) (1.11.0+cu113)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from gymnasium==0.28.1->stable-baselines3>=2.0.0->sb3-contrib) (0.0.4)\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from gymnasium==0.28.1->stable-baselines3>=2.0.0->sb3-contrib) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from gymnasium==0.28.1->stable-baselines3>=2.0.0->sb3-contrib) (4.7.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from matplotlib->stable-baselines3>=2.0.0->sb3-contrib) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from matplotlib->stable-baselines3>=2.0.0->sb3-contrib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from matplotlib->stable-baselines3>=2.0.0->sb3-contrib) (4.40.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from matplotlib->stable-baselines3>=2.0.0->sb3-contrib) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from matplotlib->stable-baselines3>=2.0.0->sb3-contrib) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from matplotlib->stable-baselines3>=2.0.0->sb3-contrib) (10.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from matplotlib->stable-baselines3>=2.0.0->sb3-contrib) (23.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from matplotlib->stable-baselines3>=2.0.0->sb3-contrib) (1.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from pandas->stable-baselines3>=2.0.0->sb3-contrib) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from pandas->stable-baselines3>=2.0.0->sb3-contrib) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3>=2.0.0->sb3-contrib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sb3-contrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (3.2.0)\n",
      "Requirement already satisfied: PyYAML in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: tqdm in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from optuna) (4.65.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from optuna) (2.0.17)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from optuna) (23.1)\n",
      "Requirement already satisfied: colorlog in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from optuna) (6.7.0)\n",
      "Requirement already satisfied: numpy in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from optuna) (1.21.2)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from optuna) (1.11.1)\n",
      "Requirement already satisfied: cmaes>=0.9.1 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from optuna) (0.9.1)\n",
      "Requirement already satisfied: typing-extensions>=4 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.7.0)\n",
      "Requirement already satisfied: Mako in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/raj/repos/HF-DeepRL/.venv/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing you need to import is the RL model, check the documentation to know what you can use on which problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO, A2C, DQN, SAC, TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithms from the contrib repo\n",
    "# https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\n",
    "from sb3_contrib import QRDQN, TQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I: The Importance Of Tuned Hyperparameters\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When compared with Supervised Learning, Deep Reinforcement Learning is far more sensitive to the choice of hyper-parameters such as learning rate, number of neurons, number of layers, optimizer ... etc. \n",
    "\n",
    "Poor choice of hyper-parameters can lead to poor/unstable convergence. This challenge is compounded by the variability in performance across random seeds (used to initialize the network weights and the environment)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to hyperparameters, selecting the appropriate algorithm is also an important choice. We will demonstrate it on the simple Pendulum task.\n",
    "\n",
    "See [gym doc](https://gym.openai.com/envs/Pendulum-v0/): \"The inverted pendulum swingup problem is a classic problem in the control literature. In this version  of the problem, the pendulum starts in a random position, and the goal is to swing it up so it stays upright.\"\n",
    "\n",
    "\n",
    "Let's try first with PPO and a small budget of 4000 steps (20 episodes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = \"Pendulum-v1\"\n",
    "# Env used only for evaluation\n",
    "eval_envs = make_vec_env(env_id, n_envs=10)\n",
    "# 4000 training timesteps\n",
    "budget_pendulum = 4000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_model = PPO(\"MlpPolicy\", env_id, seed=0, verbose=0).learn(budget_pendulum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPO Mean episode reward: -1218.55 +/- 296.81\n"
     ]
    }
   ],
   "source": [
    "mean_reward, std_reward = evaluate_policy(ppo_model, eval_envs, n_eval_episodes=100, deterministic=True)\n",
    "\n",
    "print(f\"PPO Mean episode reward: {mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and train a A2C model\n",
    "a2c_model = A2C(\"MlpPolicy\", env_id, seed=0, verbose=0).learn(budget_pendulum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2C Mean episode reward: -1511.06 +/- 42.16\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the train A2C model\n",
    "mean_reward, std_reward = evaluate_policy(a2c_model, eval_envs, n_eval_episodes=100, deterministic=True)\n",
    "print(f\"A2C Mean episode reward: {mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both are far from solving the env (mean reward around -200).\n",
    "Now, let's try with an off-policy algorithm:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training longer PPO ?\n",
    "\n",
    "Maybe training longer would help?\n",
    "\n",
    "You can try with 10x the budget, but in the case of A2C/PPO, training longer won't help much, finding better hyperparameters is needed instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train longer\n",
    "new_budget = 10 * budget_pendulum\n",
    "\n",
    "ppo_model = PPO(\"MlpPolicy\", env_id, seed=0, verbose=0).learn(new_budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPO Mean episode reward: -1228.12 +/- 325.33\n"
     ]
    }
   ],
   "source": [
    "mean_reward, std_reward = evaluate_policy(ppo_model, eval_envs, n_eval_episodes=100, deterministic=True)\n",
    "\n",
    "print(f\"PPO Mean episode reward: {mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPO - Tuned Hyperparameters\n",
    "\n",
    "Using Optuna, we can in fact tune the hyperparameters and find a working solution (from the [RL Zoo](https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/hyperparams/ppo.yml)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Creating environment from the given name 'Pendulum-v1'\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -1.18e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 379         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030145733 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.6        |\n",
      "|    explained_variance   | 0.806       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    std                  | 0.842       |\n",
      "|    value_loss           | 37.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -1.03e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027184997 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.25       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 6.33        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    std                  | 0.493       |\n",
      "|    value_loss           | 13          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -676        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042789303 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.71        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00591    |\n",
      "|    std                  | 0.3         |\n",
      "|    value_loss           | 5.88        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 200        |\n",
      "|    ep_rew_mean          | -355       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 365        |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 112        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08434065 |\n",
      "|    clip_fraction        | 0.358      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.21      |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.226      |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.0139    |\n",
      "|    std                  | 0.219      |\n",
      "|    value_loss           | 0.789      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 200         |\n",
      "|    ep_rew_mean          | -231        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048678633 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.234       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | 0.00256     |\n",
      "|    std                  | 0.177       |\n",
      "|    value_loss           | 0.917       |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tuned_params = {\n",
    "    \"gamma\": 0.9,\n",
    "    \"use_sde\": True,\n",
    "    \"sde_sample_freq\": 4,\n",
    "    \"learning_rate\": 1e-3,\n",
    "}\n",
    "\n",
    "# budget = 10 * budget_pendulum\n",
    "ppo_tuned_model = PPO(\"MlpPolicy\", env_id, seed=1, verbose=1, **tuned_params).learn(50_000, log_interval=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned PPO Mean episode reward: -166.66 +/- 105.43\n"
     ]
    }
   ],
   "source": [
    "mean_reward, std_reward = evaluate_policy(ppo_tuned_model, eval_envs, n_eval_episodes=100, deterministic=True)\n",
    "\n",
    "print(f\"Tuned PPO Mean episode reward: {mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part II: Grad Student Descent\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge (10 minutes): \"Grad Student Descent\" \n",
    "The challenge is to find the best hyperparameters (max performance) for A2C on `CartPole-v1` with a limited budget of 20 000 training steps.\n",
    "\n",
    "\n",
    "Maximum reward: 500 on `CartPole-v1`\n",
    "\n",
    "The hyperparameters should work for different random seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget = 20_000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline: default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_envs_cartpole = make_vec_env(\"CartPole-v1\", n_envs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Creating environment from the given name 'CartPole-v1'\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 28.5     |\n",
      "|    ep_rew_mean        | 28.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.691   |\n",
      "|    explained_variance | -0.359   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 2.16     |\n",
      "|    value_loss         | 13.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 26       |\n",
      "|    ep_rew_mean        | 26       |\n",
      "| time/                 |          |\n",
      "|    fps                | 359      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.693   |\n",
      "|    explained_variance | 0.0307   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 1.57     |\n",
      "|    value_loss         | 6.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 28.6     |\n",
      "|    ep_rew_mean        | 28.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 380      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.664   |\n",
      "|    explained_variance | 0.0531   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 1.5      |\n",
      "|    value_loss         | 6.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 30.7     |\n",
      "|    ep_rew_mean        | 30.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 381      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.564   |\n",
      "|    explained_variance | -0.0172  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -13.3    |\n",
      "|    value_loss         | 317      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 32.6     |\n",
      "|    ep_rew_mean        | 32.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 382      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.558   |\n",
      "|    explained_variance | 0.0515   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 0.648    |\n",
      "|    value_loss         | 5.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 35.7     |\n",
      "|    ep_rew_mean        | 35.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 388      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.569   |\n",
      "|    explained_variance | 0.0224   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -15.9    |\n",
      "|    value_loss         | 877      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 38.4     |\n",
      "|    ep_rew_mean        | 38.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 391      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.602   |\n",
      "|    explained_variance | -0.0272  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 1.29     |\n",
      "|    value_loss         | 4.31     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 40.1      |\n",
      "|    ep_rew_mean        | 40.1      |\n",
      "| time/                 |           |\n",
      "|    fps                | 391       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.649    |\n",
      "|    explained_variance | -0.000209 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 0.996     |\n",
      "|    value_loss         | 3.76      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 43.3     |\n",
      "|    ep_rew_mean        | 43.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 390      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.628   |\n",
      "|    explained_variance | -0.00108 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 0.97     |\n",
      "|    value_loss         | 3.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 46.5     |\n",
      "|    ep_rew_mean        | 46.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 390      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.636   |\n",
      "|    explained_variance | 0.000423 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 0.939    |\n",
      "|    value_loss         | 2.84     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 49.8     |\n",
      "|    ep_rew_mean        | 49.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 393      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.633   |\n",
      "|    explained_variance | 2.31e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 0.826    |\n",
      "|    value_loss         | 2.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 53.3     |\n",
      "|    ep_rew_mean        | 53.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 394      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.65    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 0.686    |\n",
      "|    value_loss         | 2.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 56.4     |\n",
      "|    ep_rew_mean        | 56.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 395      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.641   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.566    |\n",
      "|    value_loss         | 1.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 60.6     |\n",
      "|    ep_rew_mean        | 60.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 395      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.561   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.327    |\n",
      "|    value_loss         | 1.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 63.3     |\n",
      "|    ep_rew_mean        | 63.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 395      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.509   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 0.761    |\n",
      "|    value_loss         | 1.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 68.8     |\n",
      "|    ep_rew_mean        | 68.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 395      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.583   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 0.421    |\n",
      "|    value_loss         | 0.758    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 73.1     |\n",
      "|    ep_rew_mean        | 73.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 394      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.609   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.253    |\n",
      "|    value_loss         | 0.53     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 74.6     |\n",
      "|    ep_rew_mean        | 74.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 395      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.594   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 0.22     |\n",
      "|    value_loss         | 0.339    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 81.7     |\n",
      "|    ep_rew_mean        | 81.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 394      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.52    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 0.101    |\n",
      "|    value_loss         | 0.191    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 84.7     |\n",
      "|    ep_rew_mean        | 84.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 393      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.49    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 0.139    |\n",
      "|    value_loss         | 0.0846   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 89.4     |\n",
      "|    ep_rew_mean        | 89.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 393      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.45    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 0.0406   |\n",
      "|    value_loss         | 0.022    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 93.8     |\n",
      "|    ep_rew_mean        | 93.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 393      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.537   |\n",
      "|    explained_variance | 4.77e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 0.00608  |\n",
      "|    value_loss         | 0.000661 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 100      |\n",
      "|    ep_rew_mean        | 100      |\n",
      "| time/                 |          |\n",
      "|    fps                | 395      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.433   |\n",
      "|    explained_variance | 8.34e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 0.00135  |\n",
      "|    value_loss         | 1.82e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 102      |\n",
      "|    ep_rew_mean        | 102      |\n",
      "| time/                 |          |\n",
      "|    fps                | 396      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.54    |\n",
      "|    explained_variance | 0.000849 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 6.01e-05 |\n",
      "|    value_loss         | 6.2e-08  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 106      |\n",
      "|    ep_rew_mean        | 106      |\n",
      "| time/                 |          |\n",
      "|    fps                | 397      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.521   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 2.04e-05 |\n",
      "|    value_loss         | 2.56e-09 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 111      |\n",
      "|    ep_rew_mean        | 111      |\n",
      "| time/                 |          |\n",
      "|    fps                | 398      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.515   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 6.8e-06  |\n",
      "|    value_loss         | 6.4e-10  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 116      |\n",
      "|    ep_rew_mean        | 116      |\n",
      "| time/                 |          |\n",
      "|    fps                | 399      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.497   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -8.5e-06 |\n",
      "|    value_loss         | 6.4e-10  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 120       |\n",
      "|    ep_rew_mean        | 120       |\n",
      "| time/                 |           |\n",
      "|    fps                | 400       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 34        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.538    |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | -1.23e-05 |\n",
      "|    value_loss         | 6.4e-10   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 124       |\n",
      "|    ep_rew_mean        | 124       |\n",
      "| time/                 |           |\n",
      "|    fps                | 400       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.435    |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -1.94e-05 |\n",
      "|    value_loss         | 2.56e-09  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 129       |\n",
      "|    ep_rew_mean        | 129       |\n",
      "| time/                 |           |\n",
      "|    fps                | 401       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.5      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | -1.33e-05 |\n",
      "|    value_loss         | 6.4e-10   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 133       |\n",
      "|    ep_rew_mean        | 133       |\n",
      "| time/                 |           |\n",
      "|    fps                | 401       |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 38        |\n",
      "|    total_timesteps    | 15500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.529    |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | -3.01e-05 |\n",
      "|    value_loss         | 1.02e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 138       |\n",
      "|    ep_rew_mean        | 138       |\n",
      "| time/                 |           |\n",
      "|    fps                | 402       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.543    |\n",
      "|    explained_variance | 0.000958  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | -9.04e-05 |\n",
      "|    value_loss         | 1.23e-07  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 142       |\n",
      "|    ep_rew_mean        | 142       |\n",
      "| time/                 |           |\n",
      "|    fps                | 402       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 40        |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.584    |\n",
      "|    explained_variance | 0.000958  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | -0.000111 |\n",
      "|    value_loss         | 1.23e-07  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 147       |\n",
      "|    ep_rew_mean        | 147       |\n",
      "| time/                 |           |\n",
      "|    fps                | 402       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 42        |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.38     |\n",
      "|    explained_variance | 0.000584  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | -0.000195 |\n",
      "|    value_loss         | 8.97e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 156       |\n",
      "|    ep_rew_mean        | 156       |\n",
      "| time/                 |           |\n",
      "|    fps                | 402       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.401    |\n",
      "|    explained_variance | 0.000849  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | -0.000189 |\n",
      "|    value_loss         | 6.2e-08   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 159      |\n",
      "|    ep_rew_mean        | 159      |\n",
      "| time/                 |          |\n",
      "|    fps                | 403      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.317   |\n",
      "|    explained_variance | 5.25e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 0.000419 |\n",
      "|    value_loss         | 2.48e-07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 163       |\n",
      "|    ep_rew_mean        | 163       |\n",
      "| time/                 |           |\n",
      "|    fps                | 404       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 45        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.465    |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | -9.19e-06 |\n",
      "|    value_loss         | 6.4e-10   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 167      |\n",
      "|    ep_rew_mean        | 167      |\n",
      "| time/                 |          |\n",
      "|    fps                | 405      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.414   |\n",
      "|    explained_variance | 0.000584 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 5.15e-05 |\n",
      "|    value_loss         | 8.97e-08 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 171      |\n",
      "|    ep_rew_mean        | 171      |\n",
      "| time/                 |          |\n",
      "|    fps                | 405      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.519   |\n",
      "|    explained_variance | 0.000119 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 0.000494 |\n",
      "|    value_loss         | 1.74e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 175      |\n",
      "|    ep_rew_mean        | 175      |\n",
      "| time/                 |          |\n",
      "|    fps                | 406      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.262   |\n",
      "|    explained_variance | 2.91e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 0.000634 |\n",
      "|    value_loss         | 4.51e-07 |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = A2C(\"MlpPolicy\", \"CartPole-v1\", seed=8, verbose=1).learn(budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward:197.46 +/- 71.77\n"
     ]
    }
   ],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, eval_envs_cartpole, n_eval_episodes=50, deterministic=True)\n",
    "\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your goal is to beat that baseline and get closer to the optimal score of 500**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to tune!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Creating environment from the given name 'CartPole-v1'\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 28.5     |\n",
      "|    ep_rew_mean        | 28.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 431      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.691   |\n",
      "|    explained_variance | -0.359   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 2.16     |\n",
      "|    value_loss         | 13.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 26       |\n",
      "|    ep_rew_mean        | 26       |\n",
      "| time/                 |          |\n",
      "|    fps                | 464      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.693   |\n",
      "|    explained_variance | 0.0307   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 1.57     |\n",
      "|    value_loss         | 6.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 28.6     |\n",
      "|    ep_rew_mean        | 28.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 464      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.664   |\n",
      "|    explained_variance | 0.0531   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 1.5      |\n",
      "|    value_loss         | 6.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 30.7     |\n",
      "|    ep_rew_mean        | 30.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 460      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.564   |\n",
      "|    explained_variance | -0.0172  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -13.3    |\n",
      "|    value_loss         | 317      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 32.6     |\n",
      "|    ep_rew_mean        | 32.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 457      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.558   |\n",
      "|    explained_variance | 0.0515   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 0.648    |\n",
      "|    value_loss         | 5.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 35.7     |\n",
      "|    ep_rew_mean        | 35.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 453      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.569   |\n",
      "|    explained_variance | 0.0224   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -15.9    |\n",
      "|    value_loss         | 877      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 38.4     |\n",
      "|    ep_rew_mean        | 38.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 449      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.602   |\n",
      "|    explained_variance | -0.0272  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 1.29     |\n",
      "|    value_loss         | 4.31     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 40.1      |\n",
      "|    ep_rew_mean        | 40.1      |\n",
      "| time/                 |           |\n",
      "|    fps                | 445       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.649    |\n",
      "|    explained_variance | -0.000209 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 0.996     |\n",
      "|    value_loss         | 3.76      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 43.3     |\n",
      "|    ep_rew_mean        | 43.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 439      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.628   |\n",
      "|    explained_variance | -0.00108 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 0.97     |\n",
      "|    value_loss         | 3.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 46.5     |\n",
      "|    ep_rew_mean        | 46.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 438      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.636   |\n",
      "|    explained_variance | 0.000423 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 0.939    |\n",
      "|    value_loss         | 2.84     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 49.8     |\n",
      "|    ep_rew_mean        | 49.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 438      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.633   |\n",
      "|    explained_variance | 2.31e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 0.826    |\n",
      "|    value_loss         | 2.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 53.3     |\n",
      "|    ep_rew_mean        | 53.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 437      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.65    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 0.686    |\n",
      "|    value_loss         | 2.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 56.4     |\n",
      "|    ep_rew_mean        | 56.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 435      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.641   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.566    |\n",
      "|    value_loss         | 1.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 60.6     |\n",
      "|    ep_rew_mean        | 60.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 433      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.561   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.327    |\n",
      "|    value_loss         | 1.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 63.3     |\n",
      "|    ep_rew_mean        | 63.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 430      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.509   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 0.761    |\n",
      "|    value_loss         | 1.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 68.8     |\n",
      "|    ep_rew_mean        | 68.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 427      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.583   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 0.421    |\n",
      "|    value_loss         | 0.758    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 73.1     |\n",
      "|    ep_rew_mean        | 73.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 425      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.609   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.253    |\n",
      "|    value_loss         | 0.53     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 74.6     |\n",
      "|    ep_rew_mean        | 74.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 425      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.594   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 0.22     |\n",
      "|    value_loss         | 0.339    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 81.7     |\n",
      "|    ep_rew_mean        | 81.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 424      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.52    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 0.101    |\n",
      "|    value_loss         | 0.191    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 84.7     |\n",
      "|    ep_rew_mean        | 84.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 422      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.49    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 0.139    |\n",
      "|    value_loss         | 0.0846   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 89.4     |\n",
      "|    ep_rew_mean        | 89.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 422      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.45    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 0.0406   |\n",
      "|    value_loss         | 0.022    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 93.8     |\n",
      "|    ep_rew_mean        | 93.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 421      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.537   |\n",
      "|    explained_variance | 4.77e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 0.00608  |\n",
      "|    value_loss         | 0.000661 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 100      |\n",
      "|    ep_rew_mean        | 100      |\n",
      "| time/                 |          |\n",
      "|    fps                | 420      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.433   |\n",
      "|    explained_variance | 8.34e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 0.00135  |\n",
      "|    value_loss         | 1.82e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 102      |\n",
      "|    ep_rew_mean        | 102      |\n",
      "| time/                 |          |\n",
      "|    fps                | 419      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.54    |\n",
      "|    explained_variance | 0.000849 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 6.01e-05 |\n",
      "|    value_loss         | 6.2e-08  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 106      |\n",
      "|    ep_rew_mean        | 106      |\n",
      "| time/                 |          |\n",
      "|    fps                | 418      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.521   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 2.04e-05 |\n",
      "|    value_loss         | 2.56e-09 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 111      |\n",
      "|    ep_rew_mean        | 111      |\n",
      "| time/                 |          |\n",
      "|    fps                | 417      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.515   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 6.8e-06  |\n",
      "|    value_loss         | 6.4e-10  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 116      |\n",
      "|    ep_rew_mean        | 116      |\n",
      "| time/                 |          |\n",
      "|    fps                | 417      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.497   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -8.5e-06 |\n",
      "|    value_loss         | 6.4e-10  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 120       |\n",
      "|    ep_rew_mean        | 120       |\n",
      "| time/                 |           |\n",
      "|    fps                | 416       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 33        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.538    |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | -1.23e-05 |\n",
      "|    value_loss         | 6.4e-10   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 124       |\n",
      "|    ep_rew_mean        | 124       |\n",
      "| time/                 |           |\n",
      "|    fps                | 416       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 34        |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.435    |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -1.94e-05 |\n",
      "|    value_loss         | 2.56e-09  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 129       |\n",
      "|    ep_rew_mean        | 129       |\n",
      "| time/                 |           |\n",
      "|    fps                | 415       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.5      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | -1.33e-05 |\n",
      "|    value_loss         | 6.4e-10   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 133       |\n",
      "|    ep_rew_mean        | 133       |\n",
      "| time/                 |           |\n",
      "|    fps                | 414       |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 15500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.529    |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | -3.01e-05 |\n",
      "|    value_loss         | 1.02e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 138       |\n",
      "|    ep_rew_mean        | 138       |\n",
      "| time/                 |           |\n",
      "|    fps                | 413       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 38        |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.543    |\n",
      "|    explained_variance | 0.000958  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | -9.04e-05 |\n",
      "|    value_loss         | 1.23e-07  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 142       |\n",
      "|    ep_rew_mean        | 142       |\n",
      "| time/                 |           |\n",
      "|    fps                | 413       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.584    |\n",
      "|    explained_variance | 0.000958  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | -0.000111 |\n",
      "|    value_loss         | 1.23e-07  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 147       |\n",
      "|    ep_rew_mean        | 147       |\n",
      "| time/                 |           |\n",
      "|    fps                | 413       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.38     |\n",
      "|    explained_variance | 0.000584  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | -0.000195 |\n",
      "|    value_loss         | 8.97e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 156       |\n",
      "|    ep_rew_mean        | 156       |\n",
      "| time/                 |           |\n",
      "|    fps                | 413       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 42        |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.401    |\n",
      "|    explained_variance | 0.000849  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | -0.000189 |\n",
      "|    value_loss         | 6.2e-08   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 159      |\n",
      "|    ep_rew_mean        | 159      |\n",
      "| time/                 |          |\n",
      "|    fps                | 412      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.317   |\n",
      "|    explained_variance | 5.25e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 0.000419 |\n",
      "|    value_loss         | 2.48e-07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 163       |\n",
      "|    ep_rew_mean        | 163       |\n",
      "| time/                 |           |\n",
      "|    fps                | 411       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.465    |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | -9.19e-06 |\n",
      "|    value_loss         | 6.4e-10   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 167      |\n",
      "|    ep_rew_mean        | 167      |\n",
      "| time/                 |          |\n",
      "|    fps                | 411      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.414   |\n",
      "|    explained_variance | 0.000584 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 5.15e-05 |\n",
      "|    value_loss         | 8.97e-08 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 171      |\n",
      "|    ep_rew_mean        | 171      |\n",
      "| time/                 |          |\n",
      "|    fps                | 410      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.519   |\n",
      "|    explained_variance | 0.000119 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 0.000494 |\n",
      "|    value_loss         | 1.74e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 175      |\n",
      "|    ep_rew_mean        | 175      |\n",
      "| time/                 |          |\n",
      "|    fps                | 410      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.262   |\n",
      "|    explained_variance | 2.91e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 0.000634 |\n",
      "|    value_loss         | 4.51e-07 |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "policy_kwargs = dict(\n",
    "    net_arch=[\n",
    "      dict(vf=[64, 64], pi=[64, 64]), # network architectures for actor/critic\n",
    "    ],\n",
    "    activation_fn=nn.Tanh,\n",
    ")\n",
    "\n",
    "hyperparams = dict(\n",
    "    n_steps=5, # number of steps to collect data before updating policy\n",
    "    learning_rate=7e-4,\n",
    "    gamma=0.99, # discount factor\n",
    "    max_grad_norm=0.5, # The maximum value for the gradient clipping\n",
    "    ent_coef=0.0, # Entropy coefficient for the loss calculation\n",
    ")\n",
    "\n",
    "model = A2C(\"MlpPolicy\", \"CartPole-v1\", seed=8, verbose=1, **hyperparams).learn(budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward:192.20 +/- 61.49\n"
     ]
    }
   ],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, eval_envs_cartpole, n_eval_episodes=50, deterministic=True)\n",
    "\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint - Recommended Hyperparameter Range\n",
    "\n",
    "```python\n",
    "gamma = trial.suggest_float(\"gamma\", 0.9, 0.99999, log=True)\n",
    "max_grad_norm = trial.suggest_float(\"max_grad_norm\", 0.3, 5.0, log=True)\n",
    "# from 2**3 = 8 to 2**10 = 1024\n",
    "n_steps = 2 ** trial.suggest_int(\"exponent_n_steps\", 3, 10)\n",
    "learning_rate = trial.suggest_float(\"lr\", 1e-5, 1, log=True)\n",
    "ent_coef = trial.suggest_float(\"ent_coef\", 0.00000001, 0.1, log=True)\n",
    "# net_arch tiny: {\"pi\": [64], \"vf\": [64]}\n",
    "# net_arch default: {\"pi\": [64, 64], \"vf\": [64, 64]}\n",
    "# activation_fn = nn.Tanh / nn.ReLU\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part III: Automatic Hyperparameter Tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we will create a script that allows to search for the best hyperparameters automatically."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRIALS = 100 # max number of optimization trials\n",
    "N_JOBS = 1 # number of parallel jobs\n",
    "N_SARTUP_TRIALS = 5 # Stop random sampling after N_SARTUP_TRIALS and switch to TPE sampler\n",
    "N_EVALUATIONS = 2 # number of evaluations for training\n",
    "N_TIMESTEPS = int(2e4) # training budget\n",
    "EVAL_FREQ = int(N_TIMESTEPS / N_EVALUATIONS) # evaluation frequency\n",
    "N_EVAL_ENVS = 5 # number of parallel envs for evaluation\n",
    "N_EVAL_EPISODES = 10 # number of episodes for evaluation\n",
    "TIMEOUT = int(60 *15) # timeout for training in seconds\n",
    "\n",
    "ENV_ID = \"CartPole-v1\"\n",
    "\n",
    "DEFAULT_HYPERPARAMS = {\n",
    "    \"policy\": \"MlpPolicy\", # policy model to use (MlpPolicy, CnnPolicy, ...)\n",
    "    \"env\": ENV_ID, # environment ID\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def sample_a2c_params(trial: optuna.Trial) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Sampler for A2C hyperparams.\n",
    "    \n",
    "    :param trial: Optuna trial object\n",
    "    :return: Dict of hyperparams\n",
    "    \"\"\"\n",
    "    # Discount factor between 0.9 and 0.9999\n",
    "    gamma = 1.0 - trial.suggest_float(\"gamma\", 0.0001, 0.1, log=True)\n",
    "    max_grad_norm = trial.suggest_float(\"max_grad_norm\", 0.3, 5.0, log=True)\n",
    "    # 8, 16, 32, ... 1024\n",
    "    n_steps = 2 ** trial.suggest_int(\"exponent_n_steps\", 3, 10)\n",
    "\n",
    "    # define the learning rate\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "\n",
    "    # define the network architecture\n",
    "    net_arch = trial.suggest_categorical(\"net_arch\", [\"tiny\", \"small\", \"medium\", \"large\"])\n",
    "\n",
    "    # activation function\n",
    "    activation_fn = trial.suggest_categorical(\"activation_fn\", [\"tanh\", \"relu\", \"elu\", \"leaky_relu\"])\n",
    "\n",
    "    # Display true values\n",
    "    trial.set_user_attr(\"gamma_\", gamma)\n",
    "    trial.set_user_attr(\"n_steps_\", n_steps)\n",
    "\n",
    "    net_arch = [\n",
    "        {\"pi\": [64], \"vf\": [64]}\n",
    "        if net_arch == \"tiny\"\n",
    "        else {\"pi\": [64, 64], \"vf\": [64, 64]}\n",
    "    ]\n",
    "\n",
    "    activation_fn = {\"tanh\": nn.Tanh, \"relu\": nn.ReLU}[activation_fn]\n",
    "\n",
    "    return {\n",
    "        \"n_steps\": n_steps,\n",
    "        \"gamma\": gamma,\n",
    "        \"learning_rate\": lr,\n",
    "        \"max_grad_norm\": max_grad_norm,\n",
    "        \"policy_kwargs\": {\n",
    "            \"net_arch\": net_arch,\n",
    "            \"activation_fn\": activation_fn,\n",
    "        },\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
